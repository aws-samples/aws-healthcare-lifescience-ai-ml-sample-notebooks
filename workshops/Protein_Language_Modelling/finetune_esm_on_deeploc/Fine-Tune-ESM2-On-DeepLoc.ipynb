{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee72f818-0ded-401d-b350-3dcb00346260",
   "metadata": {},
   "source": [
    "# Use Amazon SageMaker for Parameter-Efficient Fine Tuning of the ESM-2 Protein Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f779d-16c6-48ae-bc6f-290855d42346",
   "metadata": {},
   "source": [
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea37b37-5093-44ec-9235-d8ba3186bb90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Note: We recommend running this notebook on a **ml.t3.medium** instance with the **Data Science 3.0** image.\n",
    "\n",
    "### What is a Protein?\n",
    "\n",
    "Proteins are complex molecules that are essential for life. The shape and structure of a protein determines what it can do in the body. Knowing how a protein is folded and how it works helps scientists design drugs that target it. For example, if a protein causes disease, a drug might be made to block its function. The drug needs to fit into the protein like a key in a lock. Understanding the protein's molecular structure reveals where drugs can attach. This knowledge helps drive the discovery of innovative new drugs.\n",
    "\n",
    "![Proteins are made up of long chains of amino acids](../img/protein.png)\n",
    "\n",
    "### What is a Protein Language Model?\n",
    "\n",
    "Proteins are made up of linear chains of molecules called amino acids, each with its own chemical structure and properties. If we think of each amino acid in a protein like a word in a sentence, it becomes possible to analyze them using methods originally developed for analyzing human language. Scientists have trained these so-called, \"Protein Language Models\", or pLMs, on millions of protein sequences from thousands of organisms. With enough data, these models can begin to capture the underlying evolutionary relationships between different amino acid sequences.\n",
    "\n",
    "It can take a lot of time and compute to train a pLM from scratch for a certain task. For example, a team at Tsinghua University [recently described](https://www.biorxiv.org/content/10.1101/2023.07.05.547496v3) training a 100 Billion-parameter pLM on 768 A100 GPUs for 164 days! Fortunately, in many cases we can save time and resources by adapting an existing pLM to our needs. This technique is called \"fine-tuning\" and also allows us to borrow advanced tools from other types of language modeling\n",
    "\n",
    "### What is ESM-2?\n",
    "\n",
    "[ESM-2](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1) is a pLM trained using unsupervied masked language modelling on 250 Million protein sequences by researchers at [Facebook AI Research (FAIR)](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1). It is available in several sizes, ranging from 8 Million to 15 Billion parameters. The smaller models are suitable for various sequence and token classification tasks. The FAIR team also adapted the 3 Billion parameter version into the ESMFold protein structure prediction algorithm. They have since used ESMFold to predict the struture of [more than 700 Million metagenomic proteins](https://esmatlas.com/about). \n",
    "\n",
    "ESM-2 is a powerful pLM. However, it has traditionally required multiple A100 GPU chips to fine-tune. In this notebook, we demonstrate how to use QLoRA to fine-tune ESM-2 in on an inexpensive Amazon SageMaker training instance. We will use ESM-2 to predict [subcellular localization](https://academic.oup.com/nar/article/50/W1/W228/6576357). Understanding where proteins appear in cells can help us understand their role in disease and find new drug targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75cb75-18ed-4211-aa13-3edfccd59e4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 1. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f744fde-5624-46e2-b5a5-6d6dc1c58b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:32:45.068665Z",
     "iopub.status.busy": "2025-04-29T16:32:45.068167Z",
     "iopub.status.idle": "2025-04-29T16:32:50.798025Z",
     "shell.execute_reply": "2025-04-29T16:32:50.796925Z",
     "shell.execute_reply.started": "2025-04-29T16:32:45.068635Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --disable-pip-version-check torch=='2.1.1+cpu' --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install --upgrade sagemaker\n",
    "%pip install transformers=='4.35.2' datasets=='2.15.0' s3fs=='0.4.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3e030-375b-4d9d-94af-784899a0d99e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:32:50.800632Z",
     "iopub.status.busy": "2025-04-29T16:32:50.799553Z",
     "iopub.status.idle": "2025-04-29T16:32:55.352461Z",
     "shell.execute_reply": "2025-04-29T16:32:55.351676Z",
     "shell.execute_reply.started": "2025-04-29T16:32:50.800583Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "smu_base_path = f\"s3://{default_bucket}/{default_prefix}/\"\n",
    "print(smu_base_path)\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "REGION_NAME = sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7165d560-0aff-4f80-8234-937de96e5053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:32:55.354390Z",
     "iopub.status.busy": "2025-04-29T16:32:55.353539Z",
     "iopub.status.idle": "2025-04-29T16:32:58.893354Z",
     "shell.execute_reply": "2025-04-29T16:32:58.892561Z",
     "shell.execute_reply.started": "2025-04-29T16:32:55.354352Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sagemaker\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.huggingface import HuggingFace, HuggingFaceModel\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from time import strftime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "try:\n",
    "    sagemaker_execution_role = sagemaker_session.get_execution_role()\n",
    "except AttributeError:\n",
    "    NOTEBOOK_METADATA_FILE = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "    with open(NOTEBOOK_METADATA_FILE, \"rb\") as f:\n",
    "        metadata = json.loads(f.read())\n",
    "        instance_name = metadata[\"ResourceName\"]\n",
    "        domain_id = metadata.get(\"DomainId\")\n",
    "        user_profile_name = metadata.get(\"UserProfileName\")\n",
    "        space_name = metadata.get(\"SpaceName\")\n",
    "    domain_desc = sagemaker_session.sagemaker_client.describe_domain(DomainId=domain_id)\n",
    "    if \"DefaultSpaceSettings\" in domain_desc:\n",
    "        sagemaker_execution_role = domain_desc[\"DefaultSpaceSettings\"][\"ExecutionRole\"]\n",
    "    else:\n",
    "        sagemaker_execution_role = domain_desc[\"DefaultUserSettings\"][\"ExecutionRole\"]\n",
    "\n",
    "print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")\n",
    "\n",
    "S3_PREFIX = \"esm-loc-ft\"\n",
    "S3_PATH = sagemaker.s3.s3_path_join(\"s3://\", S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 path is {S3_PATH}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"esm-loc-ft-\" + strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(f\"Experiment name is {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2497ac7-2c19-4668-9bf5-40c1636ce44b",
   "metadata": {},
   "source": [
    "Load the sagemaker package and create some service clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09081bc9-1dd0-490c-a0b0-07207cbbaebc",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 2. Build Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b083b46-c53a-4e3b-bd3a-11cb149b5ae2",
   "metadata": {},
   "source": [
    "We'll use a version of the [DeepLoc-2 data set](https://services.healthtech.dtu.dk/services/DeepLoc-2.0/) to fine tune our localization model. It consists of several thousand protein sequences, each with one or more experimentally-observed location labels. This data was extracted by the DeepLoc team at Technical University of Denmark from the public [UniProt sequence database](https://www.uniprot.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12bb73-8673-4bf2-8f21-082751971b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:32:58.903153Z",
     "iopub.status.busy": "2025-04-29T16:32:58.902924Z",
     "iopub.status.idle": "2025-04-29T16:33:00.954954Z",
     "shell.execute_reply": "2025-04-29T16:33:00.954200Z",
     "shell.execute_reply.started": "2025-04-29T16:32:58.903130Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://services.healthtech.dtu.dk/services/DeepLoc-2.0/data/Swissprot_Train_Validation_dataset.csv\"\n",
    ").drop([\"Unnamed: 0\", \"Partition\"], axis=1)\n",
    "df[\"Membrane\"] = df[\"Membrane\"].astype(\"int32\")\n",
    "\n",
    "# filter for sequences between 100 and 512 amino acides\n",
    "df = df[df[\"Sequence\"].apply(lambda x: len(x)).between(100, 512)]\n",
    "\n",
    "# Remove unnecessary features\n",
    "df = df[[\"Sequence\", \"Kingdom\", \"Membrane\"]]\n",
    "\n",
    "display(df)\n",
    "print(df.groupby(\"Kingdom\").size())\n",
    "print()\n",
    "print(df.groupby(\"Membrane\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0557df21-6c2e-4f5a-9b22-67f993d6ebcf",
   "metadata": {},
   "source": [
    "This looks good, but the two membrane classes are unbalanced. We could resample our data and discard records from the majority class. However, this would reduce the total training data. Instead, we'll calculate the class weights during the training job and use them to adjust the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f4051-8f4d-45bb-939e-5f24cf252022",
   "metadata": {},
   "source": [
    "Next, we tokenize the sequences and trim them to a max length of 512 amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941e433-ef3e-4d3b-9b73-19e2545eff6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:33:00.960382Z",
     "iopub.status.busy": "2025-04-29T16:33:00.960085Z",
     "iopub.status.idle": "2025-04-29T16:33:10.835078Z",
     "shell.execute_reply": "2025-04-29T16:33:10.833989Z",
     "shell.execute_reply.started": "2025-04-29T16:33:00.960352Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df).train_test_split(test_size=0.2, shuffle=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "\n",
    "def preprocess_data(examples, max_length=512):\n",
    "    text = examples[\"Sequence\"]\n",
    "    encoding = tokenizer(text, truncation=True, max_length=max_length)\n",
    "    encoding[\"labels\"] = examples[\"Membrane\"]\n",
    "    return encoding\n",
    "\n",
    "\n",
    "encoded_dataset = dataset.map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    num_proc=os.cpu_count(),\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "encoded_dataset.set_format(\"torch\")\n",
    "print(encoded_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33176a99-52de-45f8-ab38-c4a86812a7bc",
   "metadata": {},
   "source": [
    "Look at an example record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472268de-85c1-4ea9-894b-8d0e6087257a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:33:10.841051Z",
     "iopub.status.busy": "2025-04-29T16:33:10.840760Z",
     "iopub.status.idle": "2025-04-29T16:33:10.850653Z",
     "shell.execute_reply": "2025-04-29T16:33:10.849904Z",
     "shell.execute_reply.started": "2025-04-29T16:33:10.841024Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_idx = random.randint(3, len(encoded_dataset[\"train\"]))\n",
    "example = encoded_dataset[\"train\"][random_idx]\n",
    "\n",
    "print(f\"Viewing example record {random_idx}\")\n",
    "print(f\"Raw sequence:\\n{tokenizer.decode(example['input_ids'])}\\n\")\n",
    "print(f\"Tokenized sequence:\\n{example['input_ids'].tolist()}\\n\")\n",
    "print(f\"Label:\\n{example['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519980a9-32ef-4b44-a2d5-ca54bcf89790",
   "metadata": {},
   "source": [
    "Finally, we upload the processed training, test, and validation data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd371e0-2481-47c9-9c3b-4755fd51e4cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:33:10.855041Z",
     "iopub.status.busy": "2025-04-29T16:33:10.854351Z",
     "iopub.status.idle": "2025-04-29T16:33:11.964667Z",
     "shell.execute_reply": "2025-04-29T16:33:11.963872Z",
     "shell.execute_reply.started": "2025-04-29T16:33:10.855009Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_s3_uri = smu_base_path + \"esm/data/train\"\n",
    "test_s3_uri = smu_base_path + \"esm/data/test\"\n",
    "\n",
    "encoded_dataset[\"train\"].save_to_disk(train_s3_uri)\n",
    "encoded_dataset[\"test\"].save_to_disk(test_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc9cf1-76d0-4c01-9dc3-b4a0f0802a03",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 3. Train model in SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c1f99-4f6b-492c-9be0-973f941df9f4",
   "metadata": {},
   "source": [
    "Let's try a few different approaches to improving the efficiency of our fine-tuning job.\n",
    "\n",
    "### Gradient Accumulation\n",
    "\n",
    "Gradient accumulation is a training technique that allows models to simulate training on larger batch sizes. Typically, the batch size - the number of samples used to calculate the gradient in one training step - is limited by the GPU memory capacity. With gradient accumulation, the model calculates gradients on smaller batches first. Then, instead of updating the model weights right away, the gradients get accumulated over multiple small batches. Once the accumulated gradients equal the target larger batch size, the optimization step is performed to update the model. This lets models train with effectively bigger batches without exceeding the GPU memory limit. However, extra computation is needed for the smaller batch forward and backward passes. So increased batch sizes via gradient accumulation can slow down training, especially if too many accumulation steps are used. The aim is to maximize GPU usage but avoid excessive slowdowns from too many extra gradient computation steps.\n",
    "\n",
    "### Gradient Checkpointing\n",
    "\n",
    "Gradient checkpointing is a technique that reduces the memory needed during training while keeping the computational time reasonable. Large neural networks take up a lot of memory because they have to store all the intermediate values from the forward pass in order to calculate the gradients during the backward pass. This can cause memory issues. One solution is to not store these intermediate values, but then they have to be recalculated during the backward pass, which takes a lot of time. \n",
    "\n",
    "Gradient checkpointing provides a balanced approach. It saves only some of the intermediate values, called \"checkpoints,\" and recalculates the others as needed. So it uses less memory than storing everything, but also less computation than recalculating everything. By strategically selecting which activations to checkpoint, gradient checkpointing enables large neural networks to be trained with manageable memory usage and computation time. This important technique makes it feasible to train very large models that would otherwise run into memory limitations.\n",
    "\n",
    "### Low-Rank Adaptation of Large Language Models (LoRA)\n",
    "\n",
    "Large language models like ESM-2 can contain billions of parameters that are expensive to train and run. [Researchers](https://www.biorxiv.org/content/10.1101/2023.07.05.547496v3) have developed a new training method called Low-Rank Adaptation (LoRA) to make fine-tuning these huge models more efficient. \n",
    "\n",
    "The key idea behind LoRA is that when fine-tuning a model for a specific task, you don't need to update all of the original parameters. Instead, LoRA adds new smaller matrices to the model that transform the inputs and outputs. Only these smaller matrices are updated during fine-tuning, which is much faster and uses less memory. The original model parameters stay frozen. \n",
    "\n",
    "After fine-tuning with LoRA, the small adapted matrices can be merged back into the original model. Or they can be kept separate if you want to quickly fine-tune the model for other tasks without forgetting previous ones. Overall, LoRA allows large language models to be efficiently adapted to new tasks at a fraction of the usual cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd96073-8068-460a-9176-d87f232d094a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:33:11.969864Z",
     "iopub.status.busy": "2025-04-29T16:33:11.969493Z",
     "iopub.status.idle": "2025-04-29T16:33:13.041585Z",
     "shell.execute_reply": "2025-04-29T16:33:13.040800Z",
     "shell.execute_reply.started": "2025-04-29T16:33:11.969732Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"model_id\": \"facebook/esm2_t33_650M_UR50D\",\n",
    "    \"epochs\": 1,\n",
    "    \"per_device_train_batch_size\": 8,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"use_gradient_checkpointing\": True,\n",
    "    \"lora\": True,\n",
    "}\n",
    "\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"'epoch': ([0-9.]*)\"},\n",
    "    {\n",
    "        \"Name\": \"max_gpu_mem\",\n",
    "        \"Regex\": \"Max GPU memory use during training: ([0-9.e-]*) MB\",\n",
    "    },\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"'loss': ([0-9.e-]*)\"},\n",
    "    {\n",
    "        \"Name\": \"train_samples_per_second\",\n",
    "        \"Regex\": \"'train_samples_per_second': ([0-9.e-]*)\",\n",
    "    },\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"'eval_loss': ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_accuracy\", \"Regex\": \"'eval_accuracy': ([0-9.e-]*)\"},\n",
    "]\n",
    "\n",
    "hf_estimator = HuggingFace(\n",
    "    base_job_name=\"esm-2-membrane-ft\",\n",
    "    entry_point=\"lora-train.py\",\n",
    "    source_dir=\"scripts\",\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    instance_count=1,\n",
    "    transformers_version=\"4.28\",\n",
    "    pytorch_version=\"2.0\",\n",
    "    py_version=\"py310\",\n",
    "    output_path=f\"{S3_PATH}/output\",\n",
    "    role=sagemaker_execution_role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"esm-fine-tuning\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f89d80-3b2f-4360-8a47-ccf5f0120891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:39:13.574407Z",
     "iopub.status.busy": "2025-04-29T16:39:13.574109Z",
     "iopub.status.idle": "2025-04-29T16:39:16.590284Z",
     "shell.execute_reply": "2025-04-29T16:39:16.589277Z",
     "shell.execute_reply.started": "2025-04-29T16:39:13.574387Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    hf_estimator.fit(\n",
    "        {\n",
    "            \"train\": TrainingInput(s3_data=train_s3_uri, input_mode=\"File\"),\n",
    "            \"test\": TrainingInput(s3_data=test_s3_uri, input_mode=\"File\"),\n",
    "        },\n",
    "        wait=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba110cf-b9fe-4e70-8443-671a3a8a88fc",
   "metadata": {},
   "source": [
    "You can view metrics and debugging information for this run in SageMaker Experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f3fe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:39:21.253012Z",
     "iopub.status.busy": "2025-04-29T16:39:21.252742Z",
     "iopub.status.idle": "2025-04-29T16:39:21.444946Z",
     "shell.execute_reply": "2025-04-29T16:39:21.443697Z",
     "shell.execute_reply.started": "2025-04-29T16:39:21.252991Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "training_job_details = hf_estimator.latest_training_job.describe()\n",
    "print(f\"Training job name: {training_job_details.get('TrainingJobName')}\")\n",
    "print(f\"Training job status: {training_job_details.get('TrainingJobStatus')}\")\n",
    "print(f\"Training job output: {training_job_details.get('ModelArtifacts')}\")\n",
    "\n",
    "search_expression = {\n",
    "    \"Filters\": [\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Contains\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    search_expression=search_expression,\n",
    ")\n",
    "\n",
    "trial_component_analytics.dataframe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3260c9d8-bffb-465d-a60f-4886d0e7586f",
   "metadata": {},
   "source": [
    "The following table compares the different training methods we discussed above and their effect on the run time, accuracy, and GPU memory requirements of our job.\n",
    "\n",
    "| Configuration | Billable time (sec) | Evaluation Accuracy | Max GPU Memory Usage (GB)\n",
    "| ----------- | ----------- | ----------- | ----------- |\n",
    "| Base 650M model | 1698 | 0.91 | 22.6 |\n",
    "| Base + Gradient Accumulation | 1266 | 0.90 | 17.8 |\n",
    "| Base + Gradient Checkpointing | 1753 | 0.91 | 10.2|\n",
    "| Base + LoRA | 1362 | 0.90 | 18.6 |\n",
    "\n",
    "\n",
    "All of the methods produced models with high evaluation accuracy. Using LoRA decreased the run time (and cost) by 32% and using gradient checkpointing decreased the maximum GPU memory usage by 60%. Depending on our constraints (cost, time, hardware) one of these approaches may make more sense than another.\n",
    "\n",
    "Each of these methods perform well by themselves, but what happens when we use them in combination? Here are the results:\n",
    "\n",
    "| Configuration | Billable time (sec) | Evaluation Accuracy | Max GPU Memory Usage (GB)\n",
    "| ----------- | ----------- | ----------- | ----------- |\n",
    "| Base + LoRA + GA + GC | 689 | 0.80 | 3.3 |\n",
    "\n",
    "In this case, we see a 12% reduction in accuracy. However, the run time improvements are very close to what we saw with LoRA by itself. More importantly, we've reduced the GPU memory use by 85%! This is a massive decrease that allows us to train on a wide range of cost-effective instance types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca12bb0-8bec-4e33-b2a6-0542ba13b50e",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Deploy Model as Real-Time Inference Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f188d1c-fad8-4760-a4d1-8720d3082bb0",
   "metadata": {},
   "source": [
    "Finally, let's deploy our trained model to an inference endpoint and test it against some protein sequences with known subcellular localization. In this case, we'll load a previously-trained version of the model saved on the public HuggingFace model hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e17487-bd97-4cc6-a116-06945d15402c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:39:25.572465Z",
     "iopub.status.busy": "2025-04-29T16:39:25.572103Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hub = {\"HF_MODEL_ID\": \"bloyal/esm2_650M_membrane_loc\", \"HF_TASK\": \"text-classification\"}\n",
    "\n",
    "hf_model = HuggingFaceModel(\n",
    "    env=hub,\n",
    "    role=sagemaker_execution_role,\n",
    "    transformers_version=\"4.28\",\n",
    "    pytorch_version=\"2.0\",\n",
    "    py_version=\"py310\",\n",
    ")\n",
    "\n",
    "predictor = hf_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.r5.2xlarge\",\n",
    "    role=sagemaker_execution_role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a9152d-7537-443f-8348-3e766f0e4d42",
   "metadata": {},
   "source": [
    "Try running some known proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ec68e-b12f-4dc6-a58b-947cc494ad5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example cell membrane proteins\n",
    "glp_1_receptor = \"MAGAPGPLRLALLLLGMVGRAGPRPQGATVSLWETVQKWREYRRQCQRSLTEDPPPATDLFCNRTFDEYACWPDGEPGSFVNVSCPWYLPWASSVPQGHVYRFCTAEGLWLQKDNSSLPWRDLSECEESKRGERSSPEEQLLFLYIIYTVGYALSFSALVIASAILLGFRHLHCTRNYIHLNLFASFILRALSVFIKDAALKWMYSTAAQQHQWDGLLSYQDSLSCRLVFLLMQYCVAANYYWLLVEGVYLYTLLAFSVLSEQWIFRLYVSIGWGVPLLFVVPWGIVKYLYEDEGCWTRNSNMNYWLIIRLPILFAIGVNFLIFVRVICIVVSKLKANLMCKTDIKCRLAKSTLTLIPLLGTHEVIFAFVMDEHARGTLRFIKLFTELSFTSFQGLMVAILYCFVNNEVQLEFRKSWERWRLEHLHIQRDSSMKPLKCPTSSLSSGATAGSSMYTATCQASCS\"\n",
    "pd1 = \"MQIPQAPWPVVWAVLQLGWRPGWFLDSPDRPWNPPTFSPALLVVTEGDNATFTCSFSNTSESFVLNWYRMSPSNQTDKLAAFPEDRSQPGQDCRFRVTQLPNGRDFHMSVVRARRNDSGTYLCGAISLAPKAQIKESLRAELRVTERRAEVPTAHPSPSPRPAGQFQTLVVGVVGGLLGSLVLLVWVLAVICSRAARGTIGARRTGQPLKEDPSAVPVFSVDYGELDFQWREKTPEPPVPCVPEQTEYATIVFPSGMGTSSPARRGSADGPRSAQPLRPEDGHCSWPL\"\n",
    "rit1 = \"MDSGTRPVGSCCSSPAGLSREYKLVMLGAGGVGKSAMTMQFISHRFPEDHDPTIEDAYKIRIRIDDEPANLDILDTAGQAEFTAMRDQYMRAGEGFIICYSITDRRSFHEVREFKQLIYRVRRTDDTPVVLVGNKSDLKQLRQVTKEEGLALAREFSCPFFETSAAYRYYIDDVFHALVREIRRKEKEAVLAMEKKSKPKNSVWKRLKSPFRKKKDSVT\"\n",
    "\n",
    "# Example non-cell membrane proteins\n",
    "tubulin_beta_1 = \"MREIVHIQIGQCGNQIGAKFWEMIGEEHGIDLAGSDRGASALQLERISVYYNEAYGRKYVPRAVLVDLEPGTMDSIRSSKLGALFQPDSFVHGNSGAGNNWAKGHYTEGAELIENVLEVVRHESESCDCLQGFQIVHSLGGGTGSGMGTLLMNKIREEYPDRIMNSFSVMPSPKVSDTVVEPYNAVLSIHQLIENADACFCIDNEALYDICFRTLKLTTPTYGDLNHLVSLTMSGITTSLRFPGQLNADLRKLAVNMVPFPRLHFFMPGFAPLTAQGSQQYRALSVAELTQQMFDARNTMAACDLRRGRYLTVACIFRGKMSTKEVDQQLLSVQTRNSSCFVEWIPNNVKVAVCDIPPRGLSMAATFIGNNTAIQEIFNRVSEHFSAMFKRKAFVHWYTSEGMDINEFGEAENNIHDLVSEYQQFQDAKAVLEEDEEVTEEAEMEPEDKGH\"\n",
    "p53 = \"MEEPQSDPSVEPPLSQETFSDLWKLLPENNVLSPLPSQAMDDLMLSPDDIEQWFTEDPGPDEAPRMPEAAPPVAPAPAAPTPAAPAPAPSWPLSSSVPSQKTYQGSYGFRLGFLHSGTAKSVTCTYSPALNKMFCQLAKTCPVQLWVDSTPPPGTRVRAMAIYKQSQHMTEVVRRCPHHERCSDSDGLAPPQHLIRVEGNLRVEYLDDRNTFRHSVVVPYEPPEVGSDCTTIHYNYMCNSSCMGGMNRRPILTIITLEDSSGNLLGRNSFEVRVCACPGRDRRTEEENLRKKGEPHHELPPGSTKRALPNNTSSSPQPKKKPLDGEYFTLQIRGRERFEMFRELNEALELKDAQAGKEPGGSRAHSSHLKSKKGQSTSRHKKLMFKTEGPDSD\"\n",
    "adh5 = \"MANEVIKCKAAVAWEAGKPLSIEEIEVAPPKAHEVRIKIIATAVCHTDAYTLSGADPEGCFPVILGHEGAGIVESVGEGVTKLKAGDTVIPLYIPQCGECKFCLNPKTNLCQKIRVTQGKGLMPDGTSRFTCKGKTILHYMGTSTFSEYTVVADISVAKIDPLAPLDKVCLLGCGISTGYGAAVNTAKLEPGSVCAVFGLGGVGLAVIMGCKVAGASRIIGVDINKDKFARAKEFGATECINPQDFSKPIQEVLIEMTDGGVDYSFECIGNVKVMRAALEACHKGWGVSVVVGVAASGEEIATRPFQLVTGRTWKGTAFGGWKSVESVPKLVSEYMSKKIKVDEFVTHNLSFDEINKAFELMHSGKSIRTVVKI\"\n",
    "\n",
    "sample = {\"inputs\": glp_1_receptor}\n",
    "predictor.predict(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03974a",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Clean  up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473b8b6",
   "metadata": {},
   "source": [
    "Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4e10a-0152-4e03-931c-cb2820a8e337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    predictor.delete_endpoint()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203627a2-1573-41b4-9aa7-9d8e945d1384",
   "metadata": {},
   "source": [
    "Delete S3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910fdbcf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "bucket = boto_session.resource(\"s3\").Bucket(S3_BUCKET)\n",
    "bucket.objects.filter(Prefix=S3_PREFIX).delete()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
