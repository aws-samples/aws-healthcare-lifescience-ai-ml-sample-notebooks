{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Whether a Breast Cancer Sample is Benign or Malignant\n",
    "\n",
    "**Note:** This notebook was last tested with the `Python 3 (Data Science 3.0)` environment image in Amazon SageMaker Studio.\n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "1. Understand what SageMaker Script Mode is, and how it can be leveraged.\n",
    "1. Read in data from S3 to SageMaker\n",
    "1. User prebuilt SageMaker containers to build, train, and deploy a custom sklearn model\n",
    "1. Use batch transform to perform inferences and measure model performance.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This is a breast cancer diagnoses dataset, where, for each sample, the sample is diagnosed as \"Benign\" or \"Malignant\". For each sample, a number of features are given as well. The source of the dataset is the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)).\n",
    "\n",
    "For this model, we will build, train and deploy a [Multi-layer Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) using the sklearn library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure we have the latest version of sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U sagemaker>=2.48.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries and create necessary clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import model_selection\n",
    "import s3fs\n",
    "\n",
    "import sagemaker_datawrangler\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "BUCKET = sagemaker_session.default_bucket()\n",
    "PREFIX = \"breast_cancer\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3Downloader.download(\n",
    "    s3_uri=\"s3://sagemaker-sample-files/datasets/tabular/breast_cancer/wdbc.csv\",\n",
    "    local_path=\"data\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "df_data = pandas.read_csv(\n",
    "    \"data/wdbc.csv\",\n",
    "    names=[\n",
    "        \"id\",\n",
    "        \"diagnosis\",\n",
    "        \"radius_mean\",\n",
    "        \"texture_mean\",\n",
    "        \"perimeter_mean\",\n",
    "        \"area_mean\",\n",
    "        \"smoothness_mean\",\n",
    "        \"compactness_mean\",\n",
    "        \"concavity_mean\",\n",
    "        \"concave points_mean\",\n",
    "        \"symmetry_mean\",\n",
    "        \"fractal_dimension_mean\",\n",
    "        \"radius_se\",\n",
    "        \"texture_se\",\n",
    "        \"perimeter_se\",\n",
    "        \"area_se\",\n",
    "        \"smoothness_se\",\n",
    "        \"compactness_se\",\n",
    "        \"concavity_se\",\n",
    "        \"concave points_se\",\n",
    "        \"symmetry_se\",\n",
    "        \"fractal_dimension_se\",\n",
    "        \"radius_worst\",\n",
    "        \"texture_worst\",\n",
    "        \"perimeter_worst\",\n",
    "        \"area_worst\",\n",
    "        \"smoothness_worst\",\n",
    "        \"compactness_worst\",\n",
    "        \"concavity_worst\",\n",
    "        \"concave points_worst\",\n",
    "        \"symmetry_worst\",\n",
    "        \"fractal_dimension_worst\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the feature names for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(df_data.columns) - set([\"id\", \"diagnosis\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the diagnosis column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pandas.get_dummies(df_data, columns=[\"diagnosis\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data with encoded features. Malignant is now 1, Benign is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_data = df_data.rename(columns={\"diagnosis_M\": \"truth\"})\n",
    "df_data = df_data[features + [\"truth\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the feature data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training (70%) and test (30%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = model_selection.train_test_split(df_data, test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the truth column to the front of the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"truth\"] + features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_df[features]\n",
    "y_test = test_df[\"truth\"].tolist()\n",
    "print(f\"The test data has shape {x_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the training and test data to s3 so that sagemaker can read it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"data/train_data.csv\", index=False)\n",
    "training_data_path = S3Uploader.upload(\n",
    "    local_path=\"data/train_data.csv\",\n",
    "    desired_s3_uri=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "x_test.to_csv(\"data/x_test.csv\", index=False, header=False)\n",
    "test_data_path = S3Uploader.upload(\n",
    "    local_path=\"data/x_test.csv\",\n",
    "    desired_s3_uri=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument(\"--output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    train_data=pd.read_csv(os.path.join(args.train, \"train_data.csv\"))\n",
    "\n",
    "    # Extract the labels from the first column\n",
    "    train_y = train_data[\"truth\"]\n",
    "    train_X = train_data[train_data.columns[1:len(train_data)]]\n",
    "\n",
    "    # Use scikit-learn's MLP Classifier to train the model.\n",
    "    regr = MLPClassifier(random_state=1, max_iter=500).fit(train_X, train_y)\n",
    "    regr.get_params()\n",
    "\n",
    "    # Print the coefficients of the trained classifier, and save the coefficients\n",
    "    joblib.dump(regr, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    regr = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return regr\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"return the class and the probability of the class\"\"\"\n",
    "    prediction = model.predict(input_data)\n",
    "    pred_prob = model.predict_proba(input_data) # A numpy array\n",
    "    return np.array(pred_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn = SKLearn(\n",
    "    entry_point=\"train.py\",\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    py_version=\"py3\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kick off the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.fit({\"train\": training_data_path})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Batch Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a batch transformer for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = sklearn.transformer(\n",
    "    instance_count=1, instance_type=\"ml.m4.xlarge\", accept=\"text/csv\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a transform job and wait for it to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_s3 = test_data_path\n",
    "transformer.transform(batch_input_s3, content_type=\"text/csv\", split_type=\"Line\")\n",
    "print(\"Waiting for transform job: \" + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the output data from S3 to local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = transformer.output_path\n",
    "print(f\"Batch transform results saved to {batch_output}\")\n",
    "S3Downloader.download(\n",
    "    s3_uri=batch_output,\n",
    "    local_path=\"data/output\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the batch transform results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/output/*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the predictions and measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pandas.read_csv(\"data/output/x_test.csv.out\", header=None)\n",
    "predictions.reset_index(drop=True, inplace=True)\n",
    "results = pandas.concat([predictions, pandas.Series(y_test)], axis=1)\n",
    "results.columns = [\"pred_0\", \"pred_1\", \"true\"]\n",
    "results[\"true\"] = results[\"true\"].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the AUC-ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(results[\"true\"], results[\"pred_1\"])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(fpr, tpr, \"b\", label=\"AUC = %0.2f\" % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.plot([0, 1], [0, 1], \"r--\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we used SageMaker script mode to build, train, and deploy a sklearn model."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
