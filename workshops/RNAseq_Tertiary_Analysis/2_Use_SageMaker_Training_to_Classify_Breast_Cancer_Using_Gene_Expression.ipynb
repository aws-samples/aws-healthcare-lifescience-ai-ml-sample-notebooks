{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Breast Cancer Classification using Gene Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Notes:\n",
    "This notebook was created and tested on an `ml.t3.medium (2 vCPU + 4 GiB)` notebook instance running the `Python 3 (Data Science)` kernel in SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Background](#1.-Background)\n",
    "    1. [Experiments](#1.A.-Experiments)\n",
    "    1. [Jobs](#1.B.-Jobs)\n",
    "1. [Preparation](#2.-Preparation)\n",
    "    1. [Import Python Libraries](#2.A.-Import-Python-Libries)\n",
    "    1. [Create some necessary clients](#2.B.-Create-some-necessary-clients)\n",
    "    1. [Create an experiment](#2.C.-Create-an-experiment)\n",
    "    1. [Specify S3 bucket and prefix](#2.D.-Specify-S3-bucket-and-prefix)\n",
    "    1. [Define local working directories](#2.E.-Define-local-working-directories)\n",
    "1. [Data Preparation with Amazon SageMaker Processing](#3.-Data-Preparation-with-Amazon-SageMaker-Processing)\n",
    "    1. [Upload Raw Data to S3¶](#3.A.-Upload-Raw-Data-to-S3)\n",
    "    1. [Create SageMaker Processing Job Script](#3.B.-Create-SageMaker-Processing-Job-Script)\n",
    "    1. [Submit SageMaker Processing Job](#3.C.-Submit-SageMaker-Processing-Job)\n",
    "1. [Model Training](#4.-Model-Training)\n",
    "    1. [Train Model Using a SKLearn Random Forest Algorithm](#4.A.-Train-Model-Using-a-SKLearn-Random-Forest-Algorithm)\n",
    "    1. [Train Model using a Keras MLP](#4.B.-Train-Model-using-a-Keras-MLP)\n",
    "    1. [Train Model Using the XGBoost Algorithm](#4.C.-Train-Model-Using-the-XGBoost-Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Background\n",
    "In notebook 1 of this series, we demonstrated using RNAseq data to predict HER2 status using the compute resources on the notebook server. However, using notebook server resources to process large amounts of data or train complex models is generally not a good idea. It's possible to scale up your notebook server, but any time you spend on non-compute intensive tasks (i.e. most of your time) will be wasted. A better idea is to run your notebook on a small server and submit compute-intensive tasks to independent jobs. SageMaker provides managed services for running data processing, model training, and hyperparameter tuning jobs. In this notebook, we'll demonstrate how to leverage these services to optimize the performance and cost of our tasks.\n",
    "\n",
    "Specifically, we'll demonstrate two best practices: Experiments and Jobs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.A. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/experiments.png \"Experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker Experiments](https://aws.amazon.com/blogs/aws/amazon-sagemaker-experiments-organize-track-and-compare-your-machine-learning-trainings) make it as easy as possible to track data preparation and analysis steps. Organizing your ML project into experiments helps you manage large numbers of trials and alternative algorithms. Experiments also ensure that any artifacts your generate for production use can be traced back to their source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.B. Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/jobs.png \"Jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html) processing, training, and tuning jobs allow data scientists to submit compute-heavy processes to external services. This keeps costs optimized and ensures that these tasks run in reproducible environments. It also improves data scientist productivity by allowing these jobs to run in \"the background\" and provides resiliancy if something happens to your notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The Python libraries that we'll use throughout the analysis\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.A. Import Python Libraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install sagemaker-experiments\n",
    "!pip install xgboost==1.2.0 #this needs this specific version of xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from time import strftime\n",
    "from botocore.client import ClientError\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, session\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.analytics import ExperimentAnalytics, TrainingJobAnalytics\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B. Create some necessary clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "sm_session = sagemaker.session.Session()\n",
    "region = session.region_name\n",
    "role = get_execution_role()\n",
    "s3 = boto3.client('s3', region_name=region)\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.C. Create an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "brca_her2_experiment = Experiment.create(experiment_name = f\"BRCA-HER2-{create_date}\",\n",
    "                                    description = \"Predict HER2 status using TCGA RNAseq data.\",\n",
    "                                    tags = [{'Key': 'Creator', 'Value': 'bloyal'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.D. Specify S3 bucket and prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 Buckets for this project\n",
    "bucket_name = f\"brca-her2-classifier-{account_id}\"\n",
    "print(f\"S3 bucket name is {bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.E. Define local working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory is /root/RNAseq_Tertiary_Analysis\n",
      "Data directory is /root/RNAseq_Tertiary_Analysis/data\n"
     ]
    }
   ],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"data\")\n",
    "print(f\"Working directory is {WORKING_DIR}\")\n",
    "print(f\"Data directory is {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation  with Amazon SageMaker Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Processing allows you to run steps for data pre- or post-processing, feature engineering, data validation, or model evaluation workloads on Amazon SageMaker. Processing jobs accept data from Amazon S3 as input and store data into Amazon S3 as output.\n",
    "\n",
    "![processing](https://sagemaker.readthedocs.io/en/stable/_images/amazon_sagemaker_processing_image1.png)\n",
    "\n",
    "Here, we'll import the dataset and transform it with SageMaker Processing, which can be used to process terabytes of data in a SageMaker-managed cluster separate from the instance running your notebook server. In a typical SageMaker workflow, notebooks are only used for prototyping and can be run on relatively inexpensive and less powerful instances, while processing, training and model hosting tasks are run on separate, more powerful SageMaker-managed instances.  SageMaker Processing includes off-the-shelf support for Scikit-learn, as well as a Bring Your Own Container option, so it can be used with many different data transformation technologies and tasks.    \n",
    "\n",
    "To use SageMaker Processing, simply supply a Python data preprocessing script as shown below.  For this example, we're using a SageMaker prebuilt Scikit-learn container, which includes many common functions for processing data.  There are few limitations on what kinds of code and operations you can run, and only a minimal contract:  input and output data must be placed in specified directories.  If this is done, SageMaker Processing automatically loads the input data from S3 and uploads transformed data back to S3 when the job is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.A. Upload Raw Data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory is /root/RNAseq_Tertiary_Analysis\n",
      "Data directory is /root/RNAseq_Tertiary_Analysis/data\n",
      "--2022-01-18 15:38:34--  https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/HiSeqV2_PANCAN.gz\n",
      "Resolving tcga.xenahubs.net (tcga.xenahubs.net)... 3.85.156.153, 35.168.172.110, 52.2.123.35, ...\n",
      "Connecting to tcga.xenahubs.net (tcga.xenahubs.net)|3.85.156.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://tcga-xena-hub.s3.us-east-1.amazonaws.com:443/download/TCGA.BRCA.sampleMap/HiSeqV2_PANCAN.gz [following]\n",
      "--2022-01-18 15:38:34--  https://tcga-xena-hub.s3.us-east-1.amazonaws.com/download/TCGA.BRCA.sampleMap/HiSeqV2_PANCAN.gz\n",
      "Resolving tcga-xena-hub.s3.us-east-1.amazonaws.com (tcga-xena-hub.s3.us-east-1.amazonaws.com)... 52.216.30.0\n",
      "Connecting to tcga-xena-hub.s3.us-east-1.amazonaws.com (tcga-xena-hub.s3.us-east-1.amazonaws.com)|52.216.30.0|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 83389754 (80M) [binary/octet-stream]\n",
      "Saving to: ‘/root/RNAseq_Tertiary_Analysis/data/input/raw/HiSeqV2_PANCAN.gz’\n",
      "\n",
      "HiSeqV2_PANCAN.gz   100%[===================>]  79.53M  28.9MB/s    in 2.8s    \n",
      "\n",
      "2022-01-18 15:38:37 (28.9 MB/s) - ‘/root/RNAseq_Tertiary_Analysis/data/input/raw/HiSeqV2_PANCAN.gz’ saved [83389754/83389754]\n",
      "\n",
      "File ‘/root/RNAseq_Tertiary_Analysis/data/input/raw/BRCA_clinicalMatrix’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define working directories\n",
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"data\")\n",
    "print(f\"Working directory is {WORKING_DIR}\")\n",
    "print(f\"Data directory is {DATA_DIR}\")\n",
    "\n",
    "# Get TCGA BRCA Gene Expression Data\n",
    "!wget https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/HiSeqV2_PANCAN.gz -nc -P $DATA_DIR/input/raw/\n",
    "!gzip -df $DATA_DIR/input/raw/HiSeqV2_PANCAN.gz\n",
    "\n",
    "# Get TCGA BRCA Phenotype Data\n",
    "!wget https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/BRCA_clinicalMatrix -nc -P $DATA_DIR/input/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if bucket already exists. If it does not, create it\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket_name)\n",
    "except ClientError:\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"Created Bucket: {bucket_name} in Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_source = sm_session.upload_data(f\"{DATA_DIR}/input/raw/BRCA_clinicalMatrix\", bucket=bucket_name, key_prefix='data/input')\n",
    "RNAseq_source = sm_session.upload_data(f\"{DATA_DIR}/input/raw/HiSeqV2_PANCAN\", bucket=bucket_name, key_prefix='data/input')\n",
    "print(f\"Clinical phenotypes now available at {clinical_source}\")\n",
    "print(f\"Normalized expression data now available at {RNAseq_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.B. Create SageMaker Processing Job Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for processing script\n",
    "os.makedirs(os.path.join(WORKING_DIR,\"scripts/processing\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/processing/processing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/processing/processing.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--train_test_split_ratio', type=float, default=0.2)\n",
    "    parser.add_argument('--local_path', type=str, default=\"/opt/ml/processing\")\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        \n",
    "    ### Command line parser\n",
    "    args, _ = _parse_args()\n",
    "\n",
    "    DATA_DIR = os.path.join(args.local_path, \"input\")\n",
    "    print(f\"Data directory is {DATA_DIR}\")\n",
    "    \n",
    "    ### Load Gene Expression RNA-seq\n",
    "    genom = pd.read_csv(os.path.join(DATA_DIR, \"HiSeqV2_PANCAN\"), sep='\\t')\n",
    "    genom_identifiers = genom[\"sample\"].values.tolist()\n",
    "\n",
    "    ### Load Phenotypes\n",
    "    phenotypes = pd.read_csv(os.path.join(DATA_DIR, \"BRCA_clinicalMatrix\"),sep='\\t')\n",
    "\n",
    "    #### Keep `HER2_Final_Status_nature2012` target variables\n",
    "    phenotypes_subset = phenotypes[[\"sampleID\", \"HER2_Final_Status_nature2012\"]].reset_index(drop=True)\n",
    "    phenotypes_subset.fillna(\"Negative\", inplace=True)\n",
    "\n",
    "    ### Transpose Methylation and Gene Expression datasets in order to join with Phenotypes on sampleID\n",
    "    genom_transpose = genom.set_index(\"sample\").transpose().reset_index().rename(columns={\"index\": \"sampleID\"})\n",
    "\n",
    "    ### Merge datasets\n",
    "    df = pd.merge(phenotypes_subset, genom_transpose, on=\"sampleID\", how=\"left\")\n",
    "\n",
    "    ### Encode target\n",
    "    df[\"target\"] = [0 if t == \"Negative\" else 1 for t in df['HER2_Final_Status_nature2012']]\n",
    "    df = df.drop(['HER2_Final_Status_nature2012','sampleID'], axis=1)\n",
    "    ## Move target to first column\n",
    "    df.insert(loc=0, column='target', value=df.pop('target'))\n",
    "    ## Drop rows with NaN values\n",
    "    df = df.dropna()\n",
    "\n",
    "    ### Train-Valid-Test split\n",
    "    # Hold out 20% of the data for testing\n",
    "    train_df, test_df = train_test_split(df, test_size=args.train_test_split_ratio)\n",
    "    # Hold out an additional 20% of the training data for validaton\n",
    "    train_df, val_df = train_test_split(train_df, test_size=args.train_test_split_ratio)\n",
    "\n",
    "    print(f\"The training data has {train_df.shape[0]} records and {train_df.shape[1]} columns.\")\n",
    "    print(f\"The validation data has {val_df.shape[0]} records and {val_df.shape[1]} columns.\")\n",
    "    print(f\"The test data has {test_df.shape[0]} records and {test_df.shape[1]} columns.\")\n",
    "   \n",
    "    # Save data\n",
    "\n",
    "    os.makedirs(os.path.join(args.local_path, \"output/train\"), exist_ok=True)\n",
    "    training_output_path = os.path.join(args.local_path,'output/train/train.csv')\n",
    "    train_df.to_csv(training_output_path, header=True, index=False)\n",
    "    print(f\"Training data saved to {training_output_path}\")\n",
    "    \n",
    "    os.makedirs(os.path.join(args.local_path, \"output/val\"), exist_ok=True)\n",
    "    val_output_path = os.path.join(args.local_path,'output/val/val.csv')\n",
    "    val_df.to_csv(val_output_path, header=True, index=False)\n",
    "    print(f\"Validation data saved to {val_output_path}\")\n",
    "          \n",
    "    os.makedirs(os.path.join(args.local_path, \"output/test\"), exist_ok=True)\n",
    "    test_output_path = os.path.join(args.local_path,'output/test/test.csv')\n",
    "    test_df.to_csv(test_output_path, header=True, index=False)\n",
    "    print(f\"Test data saved to {test_output_path}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment to test processing script locally\n",
    "# !python scripts/processing/processing.py --local_path data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.C. Submit SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inputs for the processing job\n",
    "inputs = [ProcessingInput(source=f\"s3://{bucket_name}/data/input/\",\n",
    "                          destination='/opt/ml/processing/input',\n",
    "                          s3_data_distribution_type='ShardedByS3Key'\n",
    "                         )         \n",
    "         ]\n",
    "\n",
    "# Define the outputs for the processing job\n",
    "outputs = [ProcessingOutput(output_name='train',\n",
    "                            source='/opt/ml/processing/output/train',\n",
    "                            destination=f\"s3://{bucket_name}/data/output/train/\"\n",
    "                           ),\n",
    "           ProcessingOutput(output_name='validation',\n",
    "                            source='/opt/ml/processing/output/val',\n",
    "                            destination=f\"s3://{bucket_name}/data/output/val/\"\n",
    "                           ),\n",
    "           ProcessingOutput(output_name='test',\n",
    "                            source='/opt/ml/processing/output/test',\n",
    "                            destination=f\"s3://{bucket_name}/data/output/test/\"\n",
    "                           )\n",
    "          ]\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=1)\n",
    "\n",
    "processing_run_name = f\"Processing-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "sklearn_processor.run(\n",
    "    job_name=processing_run_name,\n",
    "    code='scripts/processing/processing.py',\n",
    "    inputs=inputs,\n",
    "    outputs=outputs, \n",
    "    experiment_config={\n",
    "        \"ExperimentName\": brca_her2_experiment.experiment_name,\n",
    "        \"TrialComponentDisplayName\": processing_run_name\n",
    "        },\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Processed Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session.download_data(f\"{DATA_DIR}/output/train\", bucket=bucket_name, key_prefix='data/output/train/train.csv')\n",
    "sm_session.download_data(f\"{DATA_DIR}/output/val\", bucket=bucket_name, key_prefix='data/output/val/val.csv')\n",
    "sm_session.download_data(f\"{DATA_DIR}/output/test\", bucket=bucket_name, key_prefix='data/output/test/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our training data is set up, we can train some models. To highlight the benefits of experiment tracking, we're going to train models using three different frameworks:\n",
    "- The XGBoost algorithm\n",
    "- The random forest model from Scikit Learm\n",
    "- A multi-layer perceptron (MLP) neural network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"text/csv\"\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket_name}/data/output/train/train.csv\", \n",
    "    content_type=content_type\n",
    ")\n",
    "\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket_name}/data/output/val/val.csv\", \n",
    "    content_type=content_type\n",
    ")\n",
    "\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket_name}/data/output/test/test.csv\", \n",
    "    content_type=content_type\n",
    ")\n",
    "\n",
    "model_output_path = f\"s3://{bucket_name}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.A. Train Model Using a SKLearn Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a trial\n",
    "rf_trial = Trial.create(\n",
    "        trial_name=f\"RF-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "        experiment_name=brca_her2_experiment.experiment_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for RF training script\n",
    "os.makedirs(os.path.join(WORKING_DIR,\"scripts/rf_train\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/rf_train/rf_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/rf_train/rf_train.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load model for inference\"\"\"\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "def _parse_args():\n",
    "    \"\"\"Parse job parameters.\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparameters are described here.\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=10)\n",
    "    parser.add_argument(\"--min-samples-leaf\", type=int, default=3)\n",
    "    \n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    \n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train.csv\")\n",
    "    parser.add_argument(\"--validation-file\", type=str, default=\"val.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test.csv\")\n",
    "    \n",
    "    parser.add_argument(\"--target\", type=str, default=\"target\")\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    try:\n",
    "        my_tracker = Tracker.load()\n",
    "    except ValueError:\n",
    "        my_tracker = Tracker.create()\n",
    "    \n",
    "    print(\"extracting arguments\")\n",
    "    args, _ = _parse_args()\n",
    "    print(args)\n",
    "\n",
    "    print(\"Preparing data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    validation_df = pd.read_csv(os.path.join(args.validation, args.validation_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "    \n",
    "    train_labels = np.array(train_df.pop(\"target\"))\n",
    "    validation_labels = np.array(validation_df.pop(\"target\"))\n",
    "    test_labels = np.array(test_df.pop(\"target\"))\n",
    "    \n",
    "    train_np = np.array(train_df)\n",
    "    validation_np = np.array(validation_df)    \n",
    "    test_np = np.array(test_df)\n",
    "        \n",
    "    # Use the scale_pos_weight parameter to account for the imbalanced classes in our data\n",
    "    pos_weight = float(np.sum(train_labels == 0) / np.sum(train_labels == 1))\n",
    "\n",
    "    # train\n",
    "    print(\"training model\")\n",
    "    classifier = RandomForestClassifier(\n",
    "        n_estimators=args.n_estimators, \n",
    "        min_samples_leaf=args.min_samples_leaf, \n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    classifier.fit(train_np, train_labels)\n",
    "    \n",
    "    print(\"Evaluating model\")\n",
    "\n",
    "    # evaluate test data\n",
    "    test_predictions = classifier.predict(test_np)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:accuracy', value=accuracy)  \n",
    "    \n",
    "    precision = precision_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:precision', value=precision) \n",
    "    \n",
    "    f1 = f1_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:f1', value=f1)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "        \n",
    "    my_tracker.close()    \n",
    "    \n",
    "    print(\"Saving model\")\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(classifier, path)\n",
    "    print(\"Model saved to \" + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `requirements.txt` file in the training script directory to install additional dependencies in the training container. This is a great way to install an extra package or two without creating your own container image from scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"sagemaker-experiments\" > scripts/rf_train/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Uncomment to test processing script locally\n",
    "# !python scripts/rf_train/rf_train.py --n-estimators 100 \\\n",
    "#                    --min-samples-leaf 2 \\\n",
    "#                    --model-dir models \\\n",
    "#                    --train \"data/output/train\" \\\n",
    "#                    --validation \"data/output/val\" \\\n",
    "#                    --test \"data/output/test\" \\\n",
    "#                    --target \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: RF-Training-Job-2022-01-18-15-45-12\n"
     ]
    }
   ],
   "source": [
    "rf_job_name= f\"RF-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "rf_estimator = SKLearn(\n",
    "    entry_point=\"rf_train.py\",\n",
    "    source_dir = \"scripts/rf_train\",   \n",
    "    output_path = model_output_path,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    enable_sagemaker_metrics=True,\n",
    "    base_job_name=rf_job_name,\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 100,\n",
    "        \"min-samples-leaf\": 3,\n",
    "        \"target\": \"target\",\n",
    "    },\n",
    ")\n",
    "\n",
    "rf_estimator.fit(\n",
    "    {'train': s3_input_train, 'validation': s3_input_validation, 'test': s3_input_test},\n",
    "    job_name=rf_job_name,\n",
    "    experiment_config={\n",
    "            \"TrialName\": rf_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": rf_job_name,\n",
    "        },\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download model\n",
    "# print(rf_job_name)\n",
    "# print(bucket_name)\n",
    "# sm_session.download_data(\"models\", bucket=bucket_name, key_prefix=f\"{rf_job_name}/output/model.tar.gz\")\n",
    "# !tar xvfz models/model.tar.gz\n",
    "# from joblib import dump, load\n",
    "# rf_model = load('model.joblib') \n",
    "# rf_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.B. Train Model using a Keras MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a trial\n",
    "tf_trial = Trial.create(\n",
    "        trial_name=f\"TF-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "        experiment_name=brca_her2_experiment.experiment_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for Keras training script\n",
    "os.makedirs(os.path.join(WORKING_DIR,\"scripts/tf_train\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/tf_train/tf_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/tf_train/tf_train.py\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical \n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, \\\n",
    " Conv1D, MaxPool1D, Flatten, concatenate\n",
    "\n",
    "def binary_mlp(metrics, output_bias=None):\n",
    "    ### Setup loss and output node activation\n",
    "\n",
    "    output_activation = \"sigmoid\"\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()#from_logits=True\n",
    "\n",
    "    \n",
    "    ### Gene Expression Encoder\n",
    "    genom_input = Input(shape = (20530,),\n",
    "                        name = 'genom_input'\n",
    "                       )\n",
    "    genom_layer = Dense(units = 64,\n",
    "                        kernel_regularizer = tf.keras.regularizers.l2(0.001),\n",
    "                        activation = 'relu',\n",
    "                        name = 'genom_layer1'\n",
    "                       )(genom_input)\n",
    "    #genom_layer = BatchNormalization(name = 'genom_layer1_normalized')(genom_layer)\n",
    "    genom_layer = Dense(units = 32,\n",
    "                        kernel_regularizer = tf.keras.regularizers.l2(0.001),\n",
    "                        activation = 'relu',\n",
    "                        name = 'genom_layer2'\n",
    "                       )(genom_layer)    \n",
    "    \n",
    "\n",
    "    X = BatchNormalization(name = 'X_normalized')(genom_layer)\n",
    "\n",
    "\n",
    "    X = Dense(units = 32,\n",
    "              activation = 'relu',\n",
    "              kernel_regularizer = tf.keras.regularizers.l2(0.001),\n",
    "              name = 'X1'\n",
    "             )(X)\n",
    "    X = Dense(units = 16,\n",
    "              activation = 'relu',\n",
    "              kernel_regularizer = tf.keras.regularizers.l2(0.001),\n",
    "              name = 'X2'\n",
    "             )(X)\n",
    "\n",
    "    output = Dense(units = 1, activation = output_activation)(X)\n",
    "    \n",
    "    ### Compile the model\n",
    "    model = tf.keras.Model(genom_input, output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss,\n",
    "                  metrics=metrics\n",
    "                 )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def _parse_args():\n",
    "    \"\"\"Parse job parameters.\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--batch_size', type=int, default=100)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1)\n",
    "\n",
    "    # input data and model directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    \n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train.csv\")\n",
    "    parser.add_argument(\"--validation-file\", type=str, default=\"val.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test.csv\")\n",
    "    \n",
    "    parser.add_argument(\"--target\", type=str, default=\"target\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    try:\n",
    "        my_tracker = Tracker.load()\n",
    "    except ValueError:\n",
    "        my_tracker = Tracker.create()\n",
    "    \n",
    "    print(\"extracting arguments\")\n",
    "    args, _ = _parse_args()\n",
    "    print(args)\n",
    "\n",
    "    print(\"Preparing data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    validation_df = pd.read_csv(os.path.join(args.validation, args.validation_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "    \n",
    "    train_labels = np.array(train_df.pop(\"target\"))\n",
    "    validation_labels = np.array(validation_df.pop(\"target\"))\n",
    "    test_labels = np.array(test_df.pop(\"target\"))\n",
    "    \n",
    "    train_np = np.array(train_df)\n",
    "    validation_np = np.array(validation_df)    \n",
    "    test_np = np.array(test_df)\n",
    "    \n",
    "    EPOCHS = 150\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    EARLY_STOPPING = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='auto',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Instantiate classifier\n",
    "    classifier = binary_mlp(metrics=[\"accuracy\", \"binary_accuracy\"], output_bias=None)    \n",
    "    \n",
    "    # Fit classifier\n",
    "    history = classifier.fit(x=train_np,\n",
    "                                y=train_labels,\n",
    "                                validation_data=(validation_np,validation_labels),\n",
    "                                callbacks=[EARLY_STOPPING],               \n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=EPOCHS,\n",
    "                                verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluating model\")\n",
    "    for epoch, value in enumerate(history.history[\"loss\"]):\n",
    "        my_tracker.log_metric(metric_name='train:loss', value=value, iteration_number=epoch)\n",
    "        \n",
    "    for epoch, value in enumerate(history.history[\"val_loss\"]):\n",
    "        my_tracker.log_metric(metric_name='validation:loss', value=value, iteration_number=epoch)        \n",
    "\n",
    "    # evaluate test data\n",
    "    test_predictions = classifier(test_np)    \n",
    "    discrete_predictions = np.around(test_predictions).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, discrete_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:accuracy', value=accuracy) \n",
    "    \n",
    "    precision = precision_score(test_labels, discrete_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:precision', value=precision)   \n",
    "    \n",
    "    f1 = f1_score(test_labels, discrete_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:f1', value=f1)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "        \n",
    "    my_tracker.close()\n",
    "    \n",
    "    print(\"Saving model\")\n",
    "    classifier.save(args.model_dir)\n",
    "    print(f\"Model saved to {args.model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"sagemaker-experiments\" > scripts/tf_train/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test locally\n",
    "# !python scripts/tf_train/tf_train.py --epochs 10 \\\n",
    "#                    --batch-size 100 \\\n",
    "#                    --learning-rate 0.1 \\\n",
    "#                    --model-dir models \\\n",
    "#                    --train \"data/output/train\" \\\n",
    "#                    --validation \"data/output/val\" \\\n",
    "#                    --test \"data/output/test\" \\\n",
    "#                    --target \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: TF-Training-Job-2022-01-18-15-45-13\n"
     ]
    }
   ],
   "source": [
    "tf_job_name= f\"TF-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "tf_estimator = TensorFlow(\n",
    "    entry_point=\"tf_train.py\",\n",
    "    source_dir=\"scripts/tf_train\",\n",
    "    output_path = model_output_path,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    enable_sagemaker_metrics=True,\n",
    "\n",
    "    framework_version=\"2.2\",\n",
    "    py_version=\"py37\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"test:accuracy\", \"Regex\": \"Accuracy: ([0-9.]+)$\"},\n",
    "        {\"Name\": \"test:precision\", \"Regex\": \"Precision: ([0-9.]+)$\"},\n",
    "        {\"Name\": \"test:f1\", \"Regex\": \"F1 Score: ([0-9.]+)$\"},        \n",
    "    ]\n",
    ")\n",
    "\n",
    "tf_estimator.fit(\n",
    "    {'train': s3_input_train, 'validation': s3_input_validation, 'test': s3_input_test},\n",
    "    job_name=tf_job_name,\n",
    "    experiment_config={\n",
    "            \"TrialName\": tf_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": tf_job_name,\n",
    "        },\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.C. Train Model Using the XGBoost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a trial\n",
    "xgb_trial = Trial.create(\n",
    "        trial_name=f\"XGBoost-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "        experiment_name=brca_her2_experiment.experiment_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for XGB training script\n",
    "os.makedirs(os.path.join(WORKING_DIR,\"scripts/xgb_train\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/xgb_train/xgb_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/xgb_train/xgb_train.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize and return fitted model.\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the _xgb_train method\n",
    "    \"\"\"\n",
    "    model_file = 'xgboost-model.pkl'\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), 'rb'))\n",
    "    return booster\n",
    "\n",
    "def _parse_args():\n",
    "    \"\"\"Parse job parameters.\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparameters are described here.\n",
    "    parser.add_argument('--objective', type=str, default=\"binary:logistic\")\n",
    "    parser.add_argument('--booster', type=str, default=\"gbtree\")\n",
    "    parser.add_argument('--eval_metric', type=str, default=\"error\")\n",
    "    parser.add_argument('--n_estimators', type=int, default=15)\n",
    "    parser.add_argument('--max_depth', type=int, default=3)\n",
    "    parser.add_argument('--min_child_weight', type=int, default=5)\n",
    "    parser.add_argument('--subsample', type=float, default=0.9)\n",
    "    parser.add_argument('--gamma', type=float, default=0.01)    \n",
    "    \n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    \n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train.csv\")\n",
    "    parser.add_argument(\"--validation-file\", type=str, default=\"val.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test.csv\")\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    try:\n",
    "        my_tracker = Tracker.load()\n",
    "    except ValueError:\n",
    "        my_tracker = Tracker.create()\n",
    "    \n",
    "    print(\"extracting arguments\")\n",
    "    args, _ = _parse_args()\n",
    "    print(args)\n",
    "\n",
    "    hyper_params_dict = {\n",
    "        'objective':             args.objective,\n",
    "        'booster':               args.booster,\n",
    "        'eval_metric':           args.eval_metric,\n",
    "        'n_estimators':          args.n_estimators,\n",
    "        'max_depth':             args.max_depth, \n",
    "        'min_child_weight':      args.min_child_weight,\n",
    "        'subsample':             args.subsample,\n",
    "        'gamma':                 args.gamma\n",
    "    }\n",
    "\n",
    "    print(\"Preparing data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    validation_df = pd.read_csv(os.path.join(args.validation, args.validation_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "    \n",
    "    train_labels = np.array(train_df.pop(\"target\"))\n",
    "    validation_labels = np.array(validation_df.pop(\"target\"))\n",
    "    test_labels = np.array(test_df.pop(\"target\"))\n",
    "    \n",
    "    train_np = np.array(train_df)\n",
    "    validation_np = np.array(validation_df)    \n",
    "    test_np = np.array(test_df)\n",
    "        \n",
    "    # Use the scale_pos_weight parameter to account for the imbalanced classes in our data\n",
    "    pos_weight = float(np.sum(train_labels == 0) / np.sum(train_labels == 1))\n",
    "\n",
    "    classifier = xgb.XGBClassifier(\n",
    "        **hyper_params_dict, \n",
    "        scale_pos_weight=pos_weight, # Use pos_weight value calculated above to account for unbalanced classes\n",
    "        use_label_encoder=False \n",
    "    )\n",
    "\n",
    "    print(\"Fitting model\")\n",
    "    classifier.fit(\n",
    "        train_np,\n",
    "        train_labels,\n",
    "        eval_set=[(train_np, train_labels), (validation_np, validation_labels)], \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluating model\")\n",
    "    results = classifier.evals_result()    \n",
    "    for epoch, value in enumerate(results[\"validation_0\"][\"error\"]):\n",
    "        my_tracker.log_metric(metric_name='train:error', value=value, iteration_number=epoch)\n",
    "        \n",
    "    for epoch, value in enumerate(results[\"validation_1\"][\"error\"]):\n",
    "        my_tracker.log_metric(metric_name='validation:error', value=value, iteration_number=epoch)\n",
    "\n",
    "    # evaluate test data\n",
    "    test_predictions = classifier.predict(test_np)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:accuracy', value=accuracy)  \n",
    "    \n",
    "    precision = precision_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:precision', value=precision)   \n",
    "    \n",
    "    f1 = f1_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:f1', value=f1)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "        \n",
    "    my_tracker.close()    \n",
    "    \n",
    "    print(\"Saving model\")\n",
    "    path = os.path.join(args.model_dir, \"xgboost-model.pkl\")\n",
    "    pkl.dump(classifier, open(path, 'wb'))\n",
    "    print(\"Model saved to \" + path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"sagemaker-experiments\" > scripts/xgb_train/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Uncomment to test processing script locally\n",
    "# !python scripts/xgb_train/xgb_train.py --objective \"binary:logistic\" --booster \"gbtree\" --eval_metric \"error\" --n_estimators 15 \\\n",
    "#   --max_depth 3 --min_child_weight 5 --subsample 0.9 --gamma 0.01 --model-dir models --train \"data/output/train\" --validation \"data/output/val\" --test \"data/output/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_job_name= f\"XGB-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "hyper_params_dict = {\n",
    "    'objective':             \"binary:logistic\",\n",
    "    'booster':               \"gbtree\",\n",
    "    'eval_metric':           \"error\",\n",
    "    'n_estimators':          15,\n",
    "    'max_depth':             3, \n",
    "    'min_child_weight':      5,\n",
    "    'subsample':             0.9,\n",
    "    'gamma':                 0.01\n",
    "}\n",
    "\n",
    "xgb_estimator = XGBoost(entry_point = \"xgb_train.py\", \n",
    "                    source_dir = \"scripts/xgb_train\",\n",
    "                    output_path = model_output_path,\n",
    "                    framework_version='1.2-1',\n",
    "                    hyperparameters=hyper_params_dict,\n",
    "                    role=role,\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.2xlarge',\n",
    "                    enable_sagemaker_metrics=True,\n",
    "                   )\n",
    "\n",
    "\n",
    "xgb_estimator.fit(\n",
    "    {'train': s3_input_train, 'validation': s3_input_validation,'test': s3_input_test},\n",
    "    job_name=xgb_job_name,\n",
    "    experiment_config={\n",
    "            \"TrialName\": xgb_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": xgb_job_name,\n",
    "        },\n",
    "    logs=True,\n",
    "    wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download XGBoost model and validate it against the test data, per Notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost-model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Download model\n",
    "sm_session.download_data(\"models\", bucket=bucket_name, key_prefix=f\"{xgb_job_name}/output/model.tar.gz\")\n",
    "!tar xvfz models/model.tar.gz -C models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"models/xgboost-model.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom function for generating a confusion matrix for a given p-value\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    if len(set(list(labels))) == 2:\n",
    "        print('Correctly un-detected (True Negatives): ', cm[0][0])\n",
    "        print('Incorrectly detected (False Positives): ', cm[0][1])\n",
    "        print('Misses (False Negatives): ', cm[1][0])\n",
    "        print('Hits (True Positives): ', cm[1][1])\n",
    "        print('Total: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{DATA_DIR}/output/test/test.csv\")\n",
    "test_labels = np.array(test_df.pop(\"target\"))\n",
    "test_np = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly un-detected (True Negatives):  211\n",
      "Incorrectly detected (False Positives):  5\n",
      "Misses (False Negatives):  8\n",
      "Hits (True Positives):  20\n",
      "Total:  28\n",
      "Accuracy: 0.95\n",
      "Precision: 0.80\n",
      "F1 Score: 0.75\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAFNCAYAAAB1+2ZJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3debxd49338c83CZHBFIkIQoQkpkdjrFJtTClqbmlSFE0FparTUzetquEuRalbq41SY6PUWBVTaq54CDHkDkmkUokjISEkMeTk/J4/1jqxHWfYZ2fts/c+6/v2Wq+z97XWvtbvnOP8cg1rXUsRgZlZnnWpdABmZpXmRGhmuedEaGa550RoZrnnRGhmuedEaGa550RoZrnnRFiFJPWQ9HdJiyTdshL1HCHp/ixjqxRJu0l6pdJxWOfkRLgSJH1T0jOSFkuqkzRB0hczqPrrQH9gnYg4rNRKIuLGiBiZQTxlJSkkbdbaMRHxWEQMW8nzjEz/gXlT0nxJj0saI6lLk+P6SLpd0hJJsyV9s5U6z5K0LP1/oHEbXLB/uKTJkpamX4evzPdg5eFEWCJJPwQuBf6bJGltBPweOCiD6jcGpkdEfQZ11TxJ3TKo49ckv6s/AZsDA4CTgd2BuyV1Lzj8d8DHJL/XI4ArJG3VSvV/jYjeBdus9JyrAncCNwBrA9cCd6blVk0iwls7N2BNYDFwWCvHdCdJlG+k26VA93TfCGAO8CNgPlAHHJvu+yXJH+Gy9BxjgLOAGwrqHgQE0C19fwwwC3gf+DdwREH54wWf2wV4GliUft2lYN/DwDnAE2k99wN9W/jeGuP/vwXxHwzsB0wHFgKnFxy/E/Ak8G567OXAqum+R9PvZUn6/X6joP6fAm8C1zeWpZ/ZND3Hdun79YG3gREtxPut9Pvp3sL+C4Ez09e90p//0IL91wPnt/DZT/1umuwbCcwFVFD2H2CfSv8/7K3J76rSAdTiBuwD1DcmohaOORuYBKwL9AP+BZyT7huRfv5sYJU0gSwF1k73N018LSbC9A/3PWBYum8AsFX6ekUiBPoA7wBHpZ8bnb5fJ93/MPAqMBTokb5v6Y+/Mf4z0/iPA94C/gKsDmwFfAgMTo/fHtg5Pe8gYBpwakF9AWzWTP0XkPyD0qMwEabHHJfW0xO4D7iold/FDGBg+voCkmT8BHBJ+vPoAbya7t8W+KDJ538M/L2Fus8i+YdlITAVOLFg3w+ACU2Ovxv4UaX/H/b26c1d49KsA7wdrXddjwDOjoj5EfEWSUvvqIL9y9L9yyLiHpLWUKljYA3A1pJ6RERdRExt5pivAjMi4vqIqI+I8cDLwAEFx/w5IqZHxAfAzUBr41nLgPMiYhlwE9AX+G1EvJ+efyqwDUBETI6ISel5XwP+CHy5iO/pFxHxURrPp0TElSQJ7imS5H9Gc5WkY49vRMTrkvYF9gU+BxwC7Al0TetfKKkv0JsksRVaRJLgm3MzsAXJP3bHAWdKGp3ua29dViFOhKVZAPRtY+xqfWB2wfvZadmKOpok0qUkfzjtEhFLSLqTJwB1kv4hafMi4mmMaYOC92+2I54FEbE8fd2YqOYV7P+g8fOShkq6O52keI9krK5vK3UDvBURH7ZxzJXA1sD/RMRHLRyzLkn3FOD/APem/zjNB+5N4+tCMoa3kOQfpDWa1LEGyXDBZ0TE/0bEGxGxPCL+BfyWZLKL9tZlleNEWJonSbp+B7dyzBskkx6NNkrLSrGEpAvYaL3CnRFxX0TsTdIyepkkQbQVT2NMc5s5NmtXkMQ1JCLWAE4H1MZnWl0fTlJvknHXq4CzJPVp4dC3SX4uAC8CX5G0rqR1SYY4egG/Au6JiAaSMc5ukoYU1PE5khZuMYJPvrepwDaSCr/XbdpRl3UQJ8ISRMQikvGx30k6WFJPSatI2jednQQYD/xMUr+0y3UmyexhKaYAX5K0kaQ1gf9q3CGpv6QDJfUCPiJphSxvpo57gKHpJT/dJH0D2JJkzKrcVicZx1yctlZPbLJ/HjD4M59q3W+ByRHxHeAfwB+aOygipgMDJQ2IiAkkrcDngbtIJmpOJGmh/Tg9fglwG3C2pF6SdiW5EuD65uqXdJCktZXYCTiFZKYYknHW5cApkrpLOjkt/2c7v1crt0oPUtbyRjIO+AxJi+1Nkj/IXdJ9qwGXkQzM16WvV0v3jaBg4D8tew3YK319Fk1mIkku6XgXmEkyFtU4WTIAeIRk7Oldkj++LdPPHMOnZ42/CExOj50MfLFg38PAdwref+qzTWL5VPxpHAEMKih7HDgyff0lkhbhYuAxkkmiwrhOSH9G7wKHt/DzWVFGkpjmAn3S973Tn8sRLcQ7Nv3dfGZyq4WyPsAd6e/1P8A3C/btBiwueD+eZKhkcfo9ntKkrm3Tn/UHwLPAtpX+/9bbZzelvyyzTk3S5SRd3DNJhja6kMzWXwDsGckkjuWUE6HlhqRDgJNIEiIklzRdEMkkh+WYE6GZ5Z4nS8ws95wIzSz3Vvpm9nJZ9vYs99lrVI/1d6t0CLYS6j+e29Y1ns0q9W92lb6DSzpfltwiNLPcq9oWoZnVmIbmruOvDU6EZpaNaKh0BCVzIjSzbDQ4EZpZzoVbhGaWe24RmlnuuUVoZrnnWWMzyz23CM0s92p4jNB3lphZJiIaStraImmgpIckTZM0VdL30/I+kh6QNCP9unZaLkmXSZop6QVJ27V1DidCM8tGQ0NpW9vqSR6BugXJY2FPkrQlcBowMSKGABPT95A8qXBIuo0leWZOq5wIzSwb0VDa1la1ySNqn01fv0/yPOsNSB7ZcG162LV88jC1g4DrIjEJWEvSAFrhMUIzy0YHzBpLGkTyHJingP4RUQdJskyfTAhJkny94GNz0rK6lup1i9DMslFii1DSWEnPFGxjm6s+fYTrrcCpEfFeK5E0t6xXq0uEuUVoZtkocdY4IsYB41o7RtIqJEnwxoi4LS2elz6mtS7t+s5Py+cAAws+viFtPFPcLUIzy0aZxgglCbgKmBYRvynYdRdwdPr6aD55nvRdwLfS2eOdgUWNXeiWuEVoZtVuV+Ao4EVJU9Ky04HzgZsljSF5/vRh6b57SB7VOhNYChzb1gmcCM0sG2W6oDoiHqf5cT+APZs5Pkge21o0J0Izy0SE7zU2s7zzvcZmlns1fK+xE6GZZcMtQjPLPa9HaGa55xahmeWexwjNLPfcIjSz3HOL0Mxyz4nQzPLOd5aYmblFaGa558kSM8s9twjNLPdquEXoFarNLPfcIjSzbLhrbGa5V8NdYydCM8uGW4RmlntOhGaWe+4am1nuuUVoZrnnFqGZ5Z5bhGaWe2VqEUq6GtgfmB8RW6dlfwWGpYesBbwbEcMlDQKmAa+k+yZFxAltncOJ0MyyUb4W4TXA5cB1jQUR8Y3G15IuBhYVHP9qRAxvzwmcCM0sG2VKhBHxaNrS+wxJAg4H9liZc/heYzPLRkRJm6Sxkp4p2Ma246y7AfMiYkZB2SaSnpP0iKTdiqnELUIzy0aJLcKIGAeMK/Gso4HxBe/rgI0iYoGk7YE7JG0VEe+1VokToZllo4NnjSV1Aw4Ftm8si4iPgI/S15MlvQoMBZ5prS4nQjPLRsdfR7gX8HJEzGkskNQPWBgRyyUNBoYAs9qqyGOEZpaNhobStjZIGg88CQyTNEfSmHTXKD7dLQb4EvCCpOeBvwEnRMTCts7hFqGZVbWIGN1C+THNlN0K3NreczgRmlk2IiodQcmcCM0sG77Fzsxyz4nQzHLPq8+YWd5Fg8cIzSzv3DU2s9xz19jMcs9dYzPLPXeNzSz3nAitUN28tzj9nIt4e+E7dJH4+kH7ctThB3PfPx/j91fdwKzZrzP+ykvZeouhALy76D1+cMZ5vPTydA7ed2/O+NF3K/wdWEtmTp/E+4sXs3x5A/X19ez8hf0qHVL18J0lVqhb16785HvHseWwzViyZCmHjzmFXXbcls0Gb8yl//1zfnnhZZ86ftVVV+V7xx3FjFmzmTlrdoWitmLttfdhLFjwTqXDqD5uEX6WpM2Bg4ANgADeAO6KiGnlOme16Ne3D/369gGgV6+eDN54IPPeWsAuO23X7PE9e6zGdp/bmv/MqevIMM2yVcOTJWVZhkvST4GbAAH/D3g6fT1e0mnlOGe1mls3j2kzXmWbrYa1fbBVvYhgwj3jeWrSBL4z5ohKh1NdoqG0rQqUq0U4BtgqIpYVFkr6DTAVOL9M560qS5d+wA/OOJefnnI8vXv1qnQ4loEvjTiYurp59Ou3DvdOuIlXXpnJY48/VemwqoNbhJ/RAKzfTPmAdF+zCh/i8qfrmq63WFuW1ddz6hnn8tWRu7P3iF0rHY5lpK5uHgBvvbWAO++cwI47tuupkZ1aNDSUtFWDcrUITwUmSpoBvJ6WbQRsBpzc0ocKH+Ky7O1ZNfvPS0Rw5q8uZfDGAzl61KGVDscy0rNnD7p06cLixUvo2bMHe+/1Zc4975JKh2UZKEsijIh7JQ0FdiKZLBEwB3g6IpaX45zV5LkXpvL3eycyZNNBfO3okwD4/vFH8/GyZfzqkitY+O4ivvuTX7D5kMGMu+Q8AEZ+7WgWL1nKsvp6/vnYvxh3yXlsusnGlfw2rIn+/fvxt1uuAqBbt67cdNMd3Hf/w5UNqprUcNdYUaXX/tRyizDveqxf1KNkrUrVfzxXpXxuyblHlvQ32+tnN5R0viz5OkIzy0YNtwidCM0sG1Uy8VEKJ0Izy4ZbhGaWe1VycXQpnAjNLBs13CIs1wXVZpYz5bqgWtLVkuZLeqmg7CxJcyVNSbf9Cvb9l6SZkl6R9JViYneL0MyyUb4W4TXA5cB1TcoviYiLCgskbQmMArYiubvtQUlD27p+2S1CM8tGQ5S2tSEiHgUWFhnFQcBNEfFRRPwbmElyY0ernAjNLBslrj5TuMZAuo0t8ownS3oh7TqvnZZtwCe39UJyR9sGbVXkRGhm2SixRRgR4yJih4JtXBFnuwLYFBgO1AEXp+XN3aXSZrPTY4RmlomOfMB7RMxrfC3pSuDu9O0cYGDBoRuSLArdKrcIzSwbZRojbI6kAQVvDwEaZ5TvAkZJ6i5pE2AIyeLQrXKL0MyyUaZb7CSNB0YAfSXNAX4BjJA0nKTb+xpwPEBETJV0M/C/QD1wUjErXjkRmlk2ytQ1jojRzRRf1crx5wHnteccToRmlg3fWWJmVrvcIjSzTFTrIs/FcCI0s2zUcNfYidDMsuFEaGZ515EXVGfNidDMsuFEaGa5V7sLVDsRmlk23DU2M3MiNLPcc9fYzPLOXWMzM7cIzSzv3CI0M3OL0MzyLpwIzSz3nAjNLO9quUXohVnNLPfcIjSzbNRwi9CJ0MwyUctdYydCM8tEp0yEkvq09sGIWJh9OGZWqzplIgQmkzw8Wc3sC2BwWSIys9oUzaWK2tBiIoyITToyEDOrbeVqEUq6GtgfmB8RW6dlFwIHAB8DrwLHRsS7kgYB04BX0o9PiogT2jpHm5fPKHGkpJ+n7zeStFMJ34+ZdWLRoJK2IlwD7NOk7AFg64jYBpgO/FfBvlcjYni6tZkEobjrCH8PfAH4Zvr+feB3xVRuZvkRDaVtbdYb8SiwsEnZ/RFRn76dBGy4MrEXkwg/HxEnAR+mAbwDrLoyJzWzzidCJW2Sxkp6pmAb285TfxuYUPB+E0nPSXpE0m7FVFDM5TPLJHUlmSBBUj9q+tJJMyuHUscII2IcMK6Uz0o6A6gHbkyL6oCNImKBpO2BOyRtFRHvtVZPMYnwMuB2oL+k84CvAz8rJWgz67yKHO/LjKSjSSZR9oyIAIiIj4CP0teTJb0KDAWeaa2uNhNhRNwoaTKwZ1p0cERMW4n4zawTig5cl1XSPsBPgS9HxNKC8n7AwohYLmkwMASY1VZ9xd5Z0hNo7B73aHfUZtbplatFKGk8MALoK2kO8AuSWeLuwAOS4JPLZL4EnC2pHlgOnFDMzR9tJkJJZwKHAbeSXFz9Z0m3RMS5JX1XZtYplSsRRsToZoqvauHYW0lyVbsU0yIcDWwbER8CSDofeBZwIjSzFTqya5y1YhLha8BqpJfPkDRHXy1XQGZWmzp6siRLrS268D8kY4IfAVMlPZC+3xt4vGPCMzMrv9ZahI3TzZNJLp9p9HDZojGzmhWddNGFazsyEDOrbZ11GS4AJA0BfgVsSTJWCEBEeBkuM1uhoYZbhMXca/xn4AqS21h2B64Dri9nUGZWe0q917gaFJMIe0TEREARMTsizgL2KG9YZlZryrgMV9kVc/nMh5K6ADMknQzMBdYtb1hmVms6+3WEp5LcYncKcA5Ja/DocgZlZrWnWlp3pShm0YWn05eLgWPLG46Z1apanixp7YLqv5OuQdiciDiwLBGZWU2qlomPUrTWIryow6Iws5rXKccII+KRjgzEzGpbp+wam5m1R2ftGpuZFa1Tdo0rrfeGX650CFai9XqvXekQrAI6ZdfYs8Zm1h6dtWvsWWMzK1qnbBF61tjM8sLLcJlZJmp4rqSoyZI/kzw+7xKSZbiOJXmanZnZCrXcNfYyXGaWiVpej9DLcJlZJmp4pf6iWoSFy3BtDxyFl+EysyYClbS1RdLVkuZLeqmgrI+kByTNSL+unZZL0mWSZkp6QdJ2xcTeZiKMiKcjYnFEzImIYyPi0IiYVEzlZpYfDVHaVoRrgH2alJ0GTIyIIcDE9D3AvsCQdBtL8piRNhUza/wQzUwIRYTHCc1shYYyzaFGxKOSBjUpPggYkb6+luQxwz9Ny6+LiAAmSVpL0oCIqGvtHMWMEf644PVqwNdIHuRkZrZCMd3c5kgaS9J6azQuIsa18bH+jcktIuokNc5bbAC8XnDcnLRs5RJhRExuUvSEJF9sbWafUupkSZr02kp8xWouG7fZAS+ma9yn4G0XkgmT9YqPy8zyoNQWYYnmNXZ5JQ0A5qflc4CBBcdtCLzRVmXFdI0nk2RUkXSJ/w2MaVfIZtbpdfDlM3eRXL1yfvr1zoLykyXdBHweWNTW+CAUlwi3iIgPCwskdW9XyGbW6ZUrEUoaTzIx0lfSHJI73c4HbpY0BvgPcFh6+D3AfsBMYClFPnCumET4L6DptThPNlNmZjlWrq5xRIxuYdeezRwbwEntPUdr6xGuRzLb0kPStnwyCLkGyQXWZmYr1PBjjVttEX4FOIZksPFiPkmE7wGnlzcsM6s15bqOsCO0th7htcC1kr4WEbd2YExmVoNqeRmuYu413l7SWo1vJK0t6dwyxmRm1qGKSYT7RsS7jW8i4h2SWRkzsxUaStyqQTGzxl0ldY+IjwAk9QB8+YyZfUqDOuEYYYEbgImS/kwyDPBt4LqyRmVmNaeWxwiLudf415JeAPYimTk+JyLuK3tkZlZTqqWbW4qiHvAeEfcC9wJI2lXS7yKi3Rctmlnn1VmvI1xB0nBgNPANknuNbytnUGZWezrldYSShgKjSBLgAuCvJA9w2r2DYjOzGtJZxwhfBh4DDoiImQCSftAhUZlZzanlrnFr1xF+DXgTeEjSlZL2xM8zNrMW1PJ1hC0mwoi4PSK+AWxO8jyAHwD9JV0haWQHxWdmNSJK3KpBMU+xWxIRN0bE/iQLMEzhkydGmZkBSde4lK0aFHOL3QoRsTAi/ugn2JlZU7XcNS7q8hkzs7ZUS1IrhROhmWUiqqSbWwonQjPLhFuEZpZ7ToRmlnvVcilMKdo1a2xm1hm5RWhmmaiWawJL4URoZpnwGKGZ5V65EqGkYSSrXzUaDJwJrAUcB7yVlp8eEfeUcg4nQjPLRLkmSyLiFWA4gKSuwFzgduBY4JKIuGhlz+FEaGaZ6KAxwj2BVyNitjJ8WJRnjc0sE6XeayxprKRnCraxrZxmFDC+4P3Jkl6QdLWktUuN3YnQzDJR6jJcETEuInYo2MY1V7+kVYEDgVvSoiuATUm6zXXAxaXG7q6xmWWiofyXVO8LPBsR8wAavwJIuhK4u9SK3SI0s0x0wDJcoynoFksaULDvEOClUmN3i9DMMlHO9qCknsDewPEFxb9On7AZwGtN9rWLE6GZZaKcF1RHxFJgnSZlR2VVvxOhmWXCt9iZWe51wGRJ2TgRmlkmajcNOhGaWUa86IKZ5V4td419HaGZ5Z5bhGaWidptDzoRmllGPEZoZrlXy2OEToRmlonaTYNOhGaWEXeNzSz3oobbhE6EZpYJtwjNLPdqebLEF1RXwCnf+w7PPfsgz05+kOuuu5zu3btXOiRrwYAN1uPmO6/moUl3MfFfdzDm+CMBWGutNfjLbVfy2NP/4C+3Xcmaa65R4Ugrr9Sl+quBE2EHW3/99TjppGP5wi77s932e9G1SxcOP/zASodlLVheX8/ZP7+Q3Xc+kANHfpOjx4xiyLDBnHTqd3jikUnstuNXeeKRSZx06phKh1pxDURJWzVwIqyArt260aPHanTt2pWePXtQVzev7Q9ZRcyf9zYvvTANgCWLlzJj+izWG9Cfkfvuzi033QnALTfdyVf226OSYVaFDliqv2w6PBFKOrajz1lN3njjTS695I/MnDGJ2a9NZtF77/Pgg49WOiwrwoYD12frbbbguckv0HfddZg/720gSZbr9OtT4egqL0r8rxpUokX4ywqcs2qstdaa7H/ASIZtvguDNtmBXj17Mnr0IZUOy9rQs1cPxl17CWedfgGL319S6XCqkluETaQPXG5uexHo38rnVjzoefnyxeUIreL22OOLvPba67z99kLq6+u5484JfGHnHSodlrWiW7dujLv2Um7/2z+YcPeDALw9fwHr9u8LwLr9+7LgrYWVDLEquEX4Wf2BbwEHNLMtaOlDhQ967tq1d5lCq6zXX5/L53falh49VgNg99135eWXZ1Q4KmvNRZedzczps7jy99etKHvg3oc5bNRBABw26iDun/BQpcKrGrXcIizXdYR3A70jYkrTHZIeLtM5a8LTT0/httvv4alJE6ivX86U51/iT1f9pdJhWQt2/Py2fH3UgUybOp37HvkbABec81suv/RP/OHqixl15KHMnVPHCcf+sMKRVl5DVEfrrhSKKg2++2oDqzMwa1O/nmtWOgRbCXMWvlTS8+iO2vjQkv5mr599W8Wff+c7S8wsE7XccnEiNLNMlPPiaEmvAe8Dy4H6iNhBUh/gr8Ag4DXg8Ih4p5T6fUG1mWWiA2aNd4+I4RHReJnFacDEiBgCTEzfl8SJ0MwyUYFZ44OAa9PX1wIHl1qRE6GZZaLUe40Lrx9Ot7HNVB/A/ZImF+zvHxF1AOnXdUuN3WOEZpaJUi+OjohxwLg2Dts1It6QtC7wgKSXSzpZC9wiNLNMlLNrHBFvpF/nA7cDOwHzJA0ASL/OLzV2J0Izy0RElLS1RVIvSas3vgZGAi8BdwFHp4cdDdxZauzuGptZJsp4+Ux/4HZJkOSsv0TEvZKeBm6WNAb4D3BYqSdwIjSzTJTrvuGImAV8rpnyBcCeWZzDidDMMlEtK8mUwonQzDJRLcvul8KJ0MwyUa0LuBTDidDMMlEtawuWwonQzDLhMUIzy71aHiP0BdVmlntuEZpZJjxZYma5V8tdYydCM8uEJ0vMLPdq+Sl2ToRmlonaTYNOhGaWEY8RmlnuORGaWe758hkzyz23CM0s93z5jJnlnrvGZpZ77hqbWe65RWhmuecWoZnlnidLzCz3avleYy/Mama550RoZpmIEv9ri6SBkh6SNE3SVEnfT8vPkjRX0pR026/U2N01NrNMlLFrXA/8KCKelbQ6MFnSA+m+SyLiopU9gROhmWWiXJMlEVEH1KWv35c0Ddggy3O4a2xmmWiIKGmTNFbSMwXb2JbOIWkQsC3wVFp0sqQXJF0tae1SY3ciNLNMlDpGGBHjImKHgm1cc/VL6g3cCpwaEe8BVwCbAsNJWowXlxq7u8ZmlolyXj4jaRWSJHhjRNwGEBHzCvZfCdxdav1uEZpZJso4ayzgKmBaRPymoHxAwWGHAC+VGrtbhGaWiYiGclW9K3AU8KKkKWnZ6cBoScNJHpfyGnB8qSdwIjSzTJTrXuOIeBxQM7vuyeocToRmlgmvPmNmuefVZ8ws99wiNLPcq+XVZ5wIzSwTXo/QzHLPXWMzyz1PlphZ7tVyi9C32JlZ7rlFaGaZ8KyxmeVeLXeNnQjNLBOeLDGz3HOL0Mxyz2OEZpZ7vrPEzHLPLUIzyz2PEZpZ7rlrbGa55xahmeWeE6GZ5V7tpkFQLWfxWiZpbESMq3QcVhr//joXrz5TOWMrHYCtFP/+OhEnQjPLPSdCM8s9J8LK8fhSbfPvrxPxZImZ5Z5bhGaWe06EFSBpH0mvSJop6bRKx2PFk3S1pPmSXqp0LJYdJ8IOJqkr8DtgX2BLYLSkLSsblbXDNcA+lQ7CsuVE2PF2AmZGxKyI+Bi4CTiowjFZkSLiUWBhpeOwbDkRdrwNgNcL3s9Jy8ysQpwIO56aKfPUvVkFORF2vDnAwIL3GwJvVCgWM8OJsBKeBoZI2kTSqsAo4K4Kx2SWa06EHSwi6oGTgfuAacDNETG1slFZsSSNB54EhkmaI2lMpWOylec7S8ws99wiNLPccyI0s9xzIjSz3HMiNLPccyI0s9xzIuwEJC2XNEXSS5JukdRzJeoaIenu9PWBra2OI2ktSd8t4RxnSfpxseVNjrlG0tfbca5BXinG2uJE2Dl8EBHDI2Jr4GPghMKdSrT7dx0Rd0XE+a0cshbQ7kRoVm2cCDufx4DN0pbQNEm/B54FBkoaKelJSc+mLcfesGJ9xJclPQ4c2liRpGMkXZ6+7i/pdknPp9suwPnApmlr9ML0uJ9IelrSC5J+WVDXGekajA8Cw9r6JiQdl9bzvKRbm7Ry95L0mKTpkvZPj+8q6cKCcx+/sj9Iyw8nwk5EUjeSdQ5fTIuGAddFxLbAEuBnwF4RsR3wDPBDSasBVwIHALsB67VQ/WXAIxHxOWA7YCpwGvBq2hr9iaSRwBCSpcaGA9tL+pKk7UluJdyWJNHuWMS3c1tE7JiebxpQeAfHIODLwFeBP6TfwxhgUUTsmNZ/nKRNijiPGd0qHYBlooekKenrx4CrgPWB2RExKS3fmWQh2CckAaxKcqvY5nuwRGcAAAGeSURBVMC/I2IGgKQbaP6ZvXsA3wKIiOXAIklrNzlmZLo9l77vTZIYVwduj4il6TmKubd6a0nnknS/e5Pcktjo5ohoAGZImpV+DyOBbQrGD9dMzz29iHNZzjkRdg4fRMTwwoI02S0pLAIeiIjRTY4bTnbLgAn4VUT8sck5Ti3hHNcAB0fE85KOAUYU7GtaV6Tn/l5EFCZMJA1q53kth9w1zo9JwK6SNgOQ1FPSUOBlYBNJm6bHjW7h8xOBE9PPdpW0BvA+SWuv0X3AtwvGHjeQtC7wKHCIpB6SVifphrdldaBO0irAEU32HSapSxrzYOCV9NwnpscjaaikXkWcx8wtwryIiLfSltV4Sd3T4p9FxHRJY4F/SHobeBzYupkqvg+MS1dbWQ6cGBFPSnoivTxlQjpOuAXwZNoiXQwcGRHPSvorMAWYTdJ9b8vPgafS41/k0wn3FeARoD9wQkR8KOlPJGOHzyo5+VvAwcX9dCzvvPqMmeWeu8ZmlntOhGaWe06EZpZ7ToRmlntOhGaWe06EZpZ7ToRmlntOhGaWe/8fn6j2aaRYMaAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "test_predictions = loaded_model.predict(test_np)\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision = precision_score(test_labels, test_predictions)\n",
    "f1 = f1_score(test_labels, test_predictions)\n",
    "\n",
    "plot_cm(test_labels, np.array(test_predictions))\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can visualize the output as well using the SageMaker Experiments console. For the XGBoost experiment, this looked like. Note that your values may differ slightly.\n",
    "\n",
    "\n",
    "![alt text](img/sm_experiments.png \"SM Experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
