{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3. Track Model Quality with SageMaker MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Automate Machine Learning Operations (MLOps) with SageMaker Pipelines.\n",
    "- Track model versions with the SageMaker Model Registry.\n",
    "- Validate model performance using SageMaker Model Monitoring and Model Lineage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Notes:\n",
    "This notebook was created and tested on an `ml.t3.medium (2 vCPU + 4 GiB)` notebook instance running the `Python 3 (Data Science)` kernel in SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Background](#1.-Background)\n",
    "    1. [Amazon SageMaker Model Building Pipelines](#1.A.-Amazon-SageMaker-Model-Building-Pipelines)\n",
    "    1. [Amazon SageMaker Model Registry](#1.B.-Amazon-SageMaker-Model-Registry)\n",
    "    1. [Amazon SageMaker Model Lineage](#1.D.-Amazon-SageMaker-Model-Lineage)\n",
    "1. [Create SageMaker MLOps Project](#2.-Create-SageMaker-MLOps-Project)\n",
    "    1. [Create a New Project Using the Build, Traing, and Deploy Template](#2.A.-Create-a-New-Project-Using-the-Build,-Traing,-and-Deploy-Template)\n",
    "    1. [Clone the New Git Repositories](#2.B.-Clone-the-New-Git-Repositories)\n",
    "    1. [Update the Build Repository](#2.C.-Update-the-Build-Repository)\n",
    "    1. [Approve the New Model Version](#2.D.-Approve-the-New-Model-Version)\n",
    "1. [Test the Model Inference Endpoint](#3.-Test-the-Model-Inference-Endpoint)\n",
    "    1. [Import Libraries and Create Clients](#3.A.-Import-Libraries-and-Create-Clients)\n",
    "    1. [Examine Model Training Reports](#3.B.-Examine-Model-Training-Reports)\n",
    "    1. [Invoke the Staging Model Endpoint](#3.C.-Invoke-the-Staging-Model-Endpoint)\n",
    "1. [Explore the Model Lineage](#4.-Explore-the-Model-Lineage)\n",
    "    1. [Visualize Lineage Entities as a Table](#4.A.-Visualize-Lineage-Entities-as-a-Table)\n",
    "    1. [Visualize Lineage Entities as a Graph](#4.B.-Visualize-Lineage-Entities-as-a-Graph)\n",
    "1. [Approve the Model Version for Release](#5.-Approve-the-Model-Version-for-Release)\n",
    "1. [Clean Up](#6.-Clean-Up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 1. Background\n",
    "\n",
    "In Notebook 2 of this series, we demonstrated how SageMaker Processing, Training, and Hyperparameter Optimization (HPO) jobs can make the development of new machine learning (ML) models faster and more cost efficient. In this notebook, we'll look at some best practices for deploying and managing your models into production. Many of these practices fall into the category of \"Machine Learning Operations\", or \"MLOps\" and are increasingly a part of many [regulatory and quality requirements](https://www.fda.gov/files/medical%20devices/published/US-FDA-Artificial-Intelligence-and-Machine-Learning-Discussion-Paper.pdf).\n",
    "\n",
    "MLOps plays a key role in the **Model Deployment** and **Model Monitoring/Maintenance** phases of the Machine Learning Lifecycle. For more information, please refer to the [Machine Learning Best Practices in Healthcare and Life Sciences Whitepaper](https://d1.awsstatic.com/whitepapers/ML-best-practices-health-science.pdf?did=wp_card&trk=wp_card).\n",
    "\n",
    "![Machine Learning Life Cycle - Part 1](img/MLLC2.png \"ML Life Cycle - Part 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Amazon SageMaker Model Building Pipelines\n",
    "\n",
    "[Amazon SageMaker Model Building Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines.html) is a tool for building machine learning pipelines that take advantage of direct SageMaker integration. Because of this integration, you can create a pipeline and set up SageMaker Projects for orchestration using a tool that handles much of the step creation and management for you. You can manage these pipelines in the SageMaker Studio UI and automatically capture data and model lineage.\n",
    "\n",
    "One of the challenges with deploying ML solutions is that their effectiveness can change over time.  For example, perhaps the distribution of your data shifts from year-to-year? Or the boundaries of a classification category? In these cases, you want to be able to quickly retrain and deploy new versions of your model, either on a schedule or in response to some event.\n",
    "\n",
    "Amazon SageMaker Pipelines allows us to define reproducible ML processes that we can trigger at will. In this example, we'll use the processing, training, and registration artifacts from above to create a pipeline and demonstrate how to execute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Amazon SageMaker Model Registry\n",
    "\n",
    "The [Amazon SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html) is a managed service that allows you to track model metadata, approve releases, and deploy new versions to production. It involves two concepts:\n",
    "\n",
    "- A **Model Package Group** is a group of models that share a common business goal. For example, you might create a model package group to track models for segmenting a specific kind of medical image.\n",
    "- A **Model Package** or **Model Version** is a member of a Model Package Group. It refers to the a specific implementation of a model with its own training artifact and/or inference container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Amazon SageMaker Model Lineage\n",
    "\n",
    "[Amazon SageMaker Model Lineage](https://docs.aws.amazon.com/sagemaker/latest/dg/lineage-tracking.html) creates and stores information about the steps of a machine learning (ML) workflow from data preparation to model deployment. With the tracking information, you can reproduce the workflow steps, track model and dataset lineage, and establish model governance and audit standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 2. Create SageMaker MLOps Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Create a New Project Using the Build, Traing, and Deploy Template\n",
    "\n",
    "Select the Home icon from the SageMaker Studio sidebar and then the Deployments group.\n",
    "\n",
    "![Resources](img/deployments.png)\n",
    "\n",
    "Select **Projects** and then **Create project**\n",
    "\n",
    "![Projects](img/projects.png)\n",
    "\n",
    "In the **SageMaker project templates** view, select the **MLOps template for model building, training, and deployment** template and then **Select Template**.\n",
    "\n",
    "![Create Project](img/create_project.png)\n",
    "\n",
    "In the **Project details** view, type `her2-brca-classifier` in the **Name** field and select **Create Project**.\n",
    "\n",
    "![Create Project](img/project_name.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the new project is starting, import some libraries and create clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --disable-pip-version-check setuptools==59.5.0 -q -q\n",
    "%pip install --disable-pip-version-check -U sagemaker jsonlines pyvis -q -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import boto3\n",
    "import jsonlines\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.lineage.context import Context, EndpointContext\n",
    "from sagemaker.lineage.lineage_trial_component import LineageTrialComponent\n",
    "from sagemaker.lineage.visualizer import LineageTableVisualizer\n",
    "from sagemaker.predictor import Predictor\n",
    "import shutil\n",
    "from time import sleep\n",
    "from visualizer.visualizer import Visualizer\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "sagemaker_execution_role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "s3_boto_client = boto_session.client(\"s3\")\n",
    "account_id = boto_session.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture some information associated with your new project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE If you use a different name for your project, please update this variable:\n",
    "project_name = \"her2-brca-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = sagemaker_boto_client.describe_project(ProjectName=project_name).get(\n",
    "    \"ProjectId\"\n",
    ")\n",
    "print(f\"SageMaker project name is {project_name}\")\n",
    "print(f\"SageMaker project ID is {project_id}\")\n",
    "\n",
    "s3_bucket = f\"sagemaker-project-{project_id}\"\n",
    "pipeline_name = f\"{project_name.lower()}-{project_id}\"\n",
    "print(f\"Pipeline name is {pipeline_name}\")\n",
    "staging_endpoint_name = f\"{project_name}-staging\"\n",
    "prod_endpoint_name = f\"{project_name}-prod\"\n",
    "build_code_path = f\"/root/{pipeline_name}/sagemaker-{pipeline_name}-modelbuild\"\n",
    "deploy_code_path = f\"/root/{pipeline_name}/sagemaker-{pipeline_name}-modeldeploy\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker will automatically create and run a default \"abalone\" template when it creates the new project, which can take as long as 15 minutes to finish. To speed things up, run the following cell to stop this pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Halt execution of default \"Abalone\" pipeline\n",
    "codepipeline_boto_client = boto3.client(\"codepipeline\")\n",
    "codepipeline_name_build = f\"sagemaker-{pipeline_name}-modelbuild\"\n",
    "pipelineExecutionId = codepipeline_boto_client.list_pipeline_executions(\n",
    "    pipelineName=codepipeline_name_build\n",
    ")[\"pipelineExecutionSummaries\"][-1][\"pipelineExecutionId\"]\n",
    "\n",
    "codepipeline_boto_client.stop_pipeline_execution(\n",
    "    pipelineName=codepipeline_name_build,\n",
    "    pipelineExecutionId=pipelineExecutionId,\n",
    "    abandon=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an overview of the services created by the project pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Building and Training Stack**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model Building and Training Stack](img/template_build.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Deployment Stack**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model Deployment Stack](img/template_deploy.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Clone the New Git Repositories\n",
    "Once the project has successfully been created, navigate to the **Repositories** tab in the project view.\n",
    "\n",
    "![Repositories](img/repositories.png)\n",
    "\n",
    "Select the **clone repo...** link for the first repository and then **Clone Repository** with the default options on the next view.\n",
    "\n",
    "![Default Repo Settings](img/repo_defaults.png)\n",
    "\n",
    "Repeat for the second repository. \n",
    "\n",
    "From the SageMaker Studio sidebar, select the **File Browser** icon. Verify that there is a new folder in your home directory named `her2-brca-classifier`, followed by the project ID. There should also be two subfolders, one for the model build steps and another for the model deploy steps.\n",
    "\n",
    "![Default Repo Settings](img/cloned_folders.png)\n",
    "\n",
    "<!-- 6. Within the build subfolder (It will be named something like `sagemaker-her2-brca-classifier-[PROJECT ID]-modelbuild`) navigate to `pipelines/abalone`. This folder will contain three files:\n",
    "- `evaluate.py`: A Python module for measuring model performance.\n",
    "- `pipeline.py`: A Python module that defines a SageMaker Pipelines model building workflow.\n",
    "- `preprocess.py`: A Python module for running a data processing job.\n",
    "\n",
    "Each of these files contains placeholder code for now. We'll update them with our own code in the next section. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Update the Build Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells to update your cloned repository with custom pipeline code and push the changes to CodeCommit. This will restart the MLOps process and build a new version of your pipeline with your custom model training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$build_code_path\" \n",
    "cp -r scripts/pipelines/her2pipeline $1/pipelines/her2pipeline\n",
    "cp scripts/pipelines/codebuild-buildspec.yml $1\n",
    "cd $1\n",
    "git config --global user.email \"awsuser@amazon.com\"\n",
    "git config --global user.name \"AWS User\"\n",
    "git add .\n",
    "git commit -a -m \"Update pipeline code\"\n",
    "git config --global credential.helper '!aws codecommit credential-helper $@'\n",
    "git config --global credential.UseHttpPath true\n",
    "git push -u origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take approximately 15 minutes to rebuild and execute the pipeline. You can track the progress either on the **Pipelines** tab of the project view or on the AWS **CodeBuild** console.\n",
    "\n",
    "![Pipeline Execution](img/pipeline_execution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Approve the New Model Version\n",
    "1. Navigate back to the project view.\n",
    "2. Select the **Model groups** tab.\n",
    "3. Double-click on the model group name (e.g. `her2-brca-classifier-[PROJECT ID]`) to view the available model versions.\n",
    "4. Double-click on model version 2 to view its details.\n",
    "5. Navigate between the **Activity**, **Model quality**, and **Settings** tabs to view information about the model inference endpoint.\n",
    "6. Select the orange **Update Status** button in the upper-right corner of the model registry view.\n",
    "7. Update the **Approved** status and (optionally) add a comment.\n",
    "\n",
    "![Update the model status](img/update-status.png \"Update the model status\")\n",
    "\n",
    "8. Wait several minutes for the \"Staging\" endpoint appear in the Endpoints tab.\n",
    "\n",
    "Real-time inference endpoints are deployed to a persistent EC2 instance. This allows them to respond quickly to requests and support a wide range of custom properties. It's a good choice for models with steady usage. However, there are other ways to deploy a model on SageMaker as well.\n",
    "\n",
    "![alt text](img/deployment_options.png \"SageMaker Model Deployment Options\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the Model Inference Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Examine Model Training Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training reports\n",
    "last_training_job_name = (\n",
    "    sagemaker_boto_client.list_training_jobs()\n",
    "    .get(\"TrainingJobSummaries\")[0]\n",
    "    .get(\"TrainingJobName\")\n",
    ")\n",
    "rule_output_path = (\n",
    "    f\"s3://sagemaker-project-{project_id}/{last_training_job_name}/rule-output\"\n",
    ")\n",
    "print(f\"Downloading training reports from {rule_output_path}\")\n",
    "sagemaker.s3.S3Downloader.download(\n",
    "    s3_uri=rule_output_path, local_path=\"training_reports/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### 3.2. Invoke the Staging Model Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test data\n",
    "recent_test_data_uri = sagemaker.s3.parse_s3_url(\n",
    "    sagemaker_boto_client.describe_processing_job(\n",
    "        ProcessingJobName=sagemaker_boto_client.list_processing_jobs(\n",
    "            NameContains=\"PreprocessHER2Data\"\n",
    "        )[\"ProcessingJobSummaries\"][-1][\"ProcessingJobName\"]\n",
    "    )[\"ProcessingOutputConfig\"][\"Outputs\"][-1][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "sagemaker_session.download_data(\n",
    "    f\"data/output/test\",\n",
    "    bucket=recent_test_data_uri[0],\n",
    "    key_prefix=f\"{recent_test_data_uri[1]}/test.csv\",\n",
    ")\n",
    "\n",
    "# Create a Predictor object for testing\n",
    "predictor = Predictor(\n",
    "    endpoint_name=staging_endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")\n",
    "\n",
    "# Load a random sample of 10 records from the test data\n",
    "test_df = pd.read_csv(\"data/output/test/test.csv\").sample(n=25)\n",
    "\n",
    "# Submit the 10 samples to the inference endpoint and compare the actual and predicted values\n",
    "print(\n",
    "    \"Sending test traffic to the endpoint {}. \\nPlease wait...\".format(\n",
    "        staging_endpoint_name\n",
    "    )\n",
    ")\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    print(\n",
    "        f\"[Actual | predicted] labels for record {i:3} are [{row[0]} | {predictor.predict(row.iloc[1:]):.3f}]\"\n",
    "    )\n",
    "    sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the monitoring data to finish processing. This will take about a minute to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch the S3 bucket we specified above for storing monitoring data\n",
    "endpoint_capture_uri = (\n",
    "    sagemaker_boto_client.describe_endpoint(EndpointName=staging_endpoint_name)\n",
    "    .get(\"DataCaptureConfig\")\n",
    "    .get(\"DestinationS3Uri\")\n",
    ")\n",
    "endpoint_capture_bucket = sagemaker.s3.parse_s3_url(endpoint_capture_uri)[0]\n",
    "endpoint_capture_prefix = sagemaker.s3.parse_s3_url(endpoint_capture_uri)[1]\n",
    "result = {}\n",
    "while result.get(\"Contents\") is None:\n",
    "    print(\"Waiting for endpoint monitoring data to populate...\")\n",
    "    result = s3_boto_client.list_objects(\n",
    "        Bucket=endpoint_capture_bucket, Prefix=endpoint_capture_prefix\n",
    "    )\n",
    "    sleep(10)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the contents of the first data capture file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the monitoring data from S3\n",
    "sagemaker_session.download_data(\n",
    "    \"data\", bucket=endpoint_capture_bucket, key_prefix=capture_files[0]\n",
    ")\n",
    "runs = []\n",
    "\n",
    "# Open the jsonlines file and summarize the contents\n",
    "with jsonlines.open(f\"data/{os.path.basename(capture_files[0])}\") as reader:\n",
    "    [runs.append(obj) for obj in reader]\n",
    "\n",
    "print(f\"Number of runs captured in file: {len(runs)}\")\n",
    "print(f\"First event metadata: {runs[0]['eventMetadata']}\")\n",
    "\n",
    "first_request = runs[0][\"captureData\"][\"endpointInput\"][\"data\"]\n",
    "print(f\"First event input: {first_request[:2000]}...\")\n",
    "\n",
    "first_response = runs[0][\"captureData\"][\"endpointOutput\"][\"data\"]\n",
    "\n",
    "print(f\"First event output: {first_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resubmit the data from the first prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(first_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 4. Explore the Model Lineage\n",
    "\n",
    "Effective model governance requires a detailed understanding of the data and data transformations used in the modeling process, in addition to nearly continuous tracking of all model development iterations. It is important to keep track of which dataset was used, what transformations were applied to the data, where the dataset was stored, and what type of model was built. This metadata that tracks the relationships between various entities in your ML workflows is called the \"lineage\".\n",
    "\n",
    "In this section, we'll explore the model artifacts and events that Amazon SageMaker ML Lineage Tracking creates for us automatically. We'll also see how to expand the lineage by manually adding additional artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Visualize Lineage Entities as a Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker automatically creates tracking entities for SageMaker jobs, models, model packages, and endpoints if the data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow import pipeline\n",
    "\n",
    "pipeline_execution_arn = (\n",
    "    sagemaker_boto_client.list_pipeline_executions(PipelineName=pipeline_name)\n",
    "    .get(\"PipelineExecutionSummaries\")[0]\n",
    "    .get(\"PipelineExecutionArn\")\n",
    ")\n",
    "\n",
    "execution = sagemaker.workflow.pipeline._PipelineExecution(arn=pipeline_execution_arn)\n",
    "table_viz = LineageTableVisualizer(sagemaker_session=sagemaker_session)\n",
    "for execution_step in reversed(execution.list_steps()):\n",
    "    print(execution_step.get(\"StepName\"))\n",
    "    display(table_viz.show(pipeline_execution_step=execution_step))\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Visualize Lineage Entities as a Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the ML lineage as a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_info = sagemaker_boto_client.describe_endpoint(\n",
    "    EndpointName=staging_endpoint_name\n",
    ")\n",
    "endpoint_arn = endpoint_info[\"EndpointArn\"]\n",
    "print(f\"Endpoint Name: {endpoint_info['EndpointName']}\")\n",
    "\n",
    "# Get the endpoint context for querying the lineage graph\n",
    "contexts = Context.list(source_uri=endpoint_arn, sagemaker_session=sagemaker_session)\n",
    "context_name = list(contexts)[0].context_name\n",
    "\n",
    "viz = Visualizer()\n",
    "print(\"Querying lineage for context\", context_name)\n",
    "endpoint_context = EndpointContext.load(\n",
    "    context_name=context_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "query_response = sagemaker_boto_client.query_lineage(\n",
    "    StartArns=[endpoint_context.context_arn],\n",
    "    Direction=\"Ascendants\",\n",
    "    IncludeEdges=True,\n",
    ")\n",
    "viz.render(query_response, \"Endpoint\", sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (Optional) Deploy to Production\n",
    "1. In the AWS Console, search for and select **CodePipeline**.\n",
    "\n",
    "![Search for CodePipeline](img/code-pipeline.png)\n",
    "\n",
    "2. Navigate to **Pipeline > Pipelines** and select the model deploy pipeline already in progress.\n",
    "\n",
    "![Find Prod Deploy Pipeline](img/find-prod-deploy.png)\n",
    "\n",
    "3. Scroll down to the **DeployStaging** stage and select Review.\n",
    "\n",
    "![Select Review](img/deploy-stage.png)\n",
    "\n",
    "4. Select **Approve** in the Review view.\n",
    "\n",
    "![Approve Prod Deployment](img/approve-prod.png)\n",
    "\n",
    "5. Navigate back to the SageMaker Project view. After several minutes, a second \"prod\" endpoint will appear.\n",
    "\n",
    "![Second Endpoint](img/second-endpoint.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model registry records\n",
    "for package in sagemaker_boto_client.list_model_packages(\n",
    "    ModelPackageGroupName=pipeline_name\n",
    ").get(\"ModelPackageSummaryList\"):\n",
    "    print(package)\n",
    "    sagemaker_boto_client.delete_model_package(\n",
    "        ModelPackageName=package.get(\"ModelPackageArn\")\n",
    "    )\n",
    "sagemaker_boto_client.delete_model_package_group(ModelPackageGroupName=pipeline_name)\n",
    "\n",
    "# Delete endpoint\n",
    "predictor.delete_endpoint()\n",
    "\n",
    "# Delete pipeline\n",
    "sagemaker_boto_client.delete_pipeline(PipelineName=pipeline_name)\n",
    "\n",
    "# Delete all S3 objects\n",
    "bucket = boto_session.resource(\"s3\").Bucket(s3_bucket)\n",
    "bucket.objects.filter().delete()\n",
    "bucket.delete()\n",
    "\n",
    "# Delete Project\n",
    "sagemaker_boto_client.delete_project(ProjectName=project_name)\n",
    "\n",
    "# Delete deployment infrastructure\n",
    "cfn = boto3.client(\"cloudformation\")\n",
    "cfn.delete_stack(StackName=f\"sagemaker-{project_name}-{project_id}-deploy-staging\")\n",
    "cfn.delete_stack(StackName=f\"sagemaker-{project_name}-{project_id}-deploy-prod\")\n",
    "\n",
    "# Delete local  objects\n",
    "os.system(f\"rm -rf ~/{project_name}-{project_id}\")\n",
    "os.system(\"rm -rf data models generated training_reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "fcd20795596b30c7734a8efd08df92d501ca130112f67abeee93ccff645bf25b"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
